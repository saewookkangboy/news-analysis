"""
íƒ€ê²Ÿ ë¶„ì„ ì„œë¹„ìŠ¤
AIë¥¼ ì‚¬ìš©í•˜ì—¬ í‚¤ì›Œë“œ, ì˜¤ë””ì–¸ìŠ¤, ê²½ìŸì ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
"""
import os
import logging
from typing import Optional, Dict, Any
import json

from backend.config import settings
from backend.services.progress_tracker import ProgressTracker
from backend.utils.token_optimizer import (
    optimize_prompt, estimate_tokens, get_max_tokens_for_model, optimize_additional_context
)

logger = logging.getLogger(__name__)


async def analyze_target(
    target_keyword: str,
    target_type: str = "keyword",
    additional_context: Optional[str] = None,
    use_gemini: bool = False,
    start_date: Optional[str] = None,
    end_date: Optional[str] = None,
    progress_tracker: Optional[ProgressTracker] = None
) -> Dict[str, Any]:
    """
    íƒ€ê²Ÿ ë¶„ì„ ìˆ˜í–‰
    
    Args:
        target_keyword: ë¶„ì„í•  íƒ€ê²Ÿ í‚¤ì›Œë“œ ë˜ëŠ” ì£¼ì œ
        target_type: ë¶„ì„ ìœ í˜• (keyword, audience, competitor)
        additional_context: ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸ ì •ë³´
        use_gemini: Gemini API ì‚¬ìš© ì—¬ë¶€ (Trueì¼ ê²½ìš° OpenAI + Gemini ë³´ì™„ ë¶„ì„)
        start_date: ë¶„ì„ ì‹œì‘ì¼ (YYYY-MM-DD í˜•ì‹)
        end_date: ë¶„ì„ ì¢…ë£Œì¼ (YYYY-MM-DD í˜•ì‹)
        progress_tracker: ì§„í–‰ ìƒí™© ì¶”ì  ê°ì²´
        
    Returns:
        ë¶„ì„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    """
    try:
        logger.info(f"íƒ€ê²Ÿ ë¶„ì„ ì‹œì‘: {target_keyword} (íƒ€ì…: {target_type}, Gemini ë³´ì™„: {use_gemini})")
        
        # API í‚¤ ìƒíƒœ í™•ì¸ ë° ë¡œê¹… (í™˜ê²½ ë³€ìˆ˜ì—ì„œ ì§ì ‘ í™•ì¸ - Vercel í˜¸í™˜ì„±)
        # ì—¬ëŸ¬ ì†ŒìŠ¤ì—ì„œ API í‚¤ í™•ì¸ (ìš°ì„ ìˆœìœ„: í™˜ê²½ ë³€ìˆ˜ > Settings)
        openai_env = os.getenv('OPENAI_API_KEY')
        gemini_env = os.getenv('GEMINI_API_KEY')
        openai_settings = getattr(settings, 'OPENAI_API_KEY', None)
        gemini_settings = getattr(settings, 'GEMINI_API_KEY', None)
        
        openai_key = openai_env or openai_settings
        gemini_key = gemini_env or gemini_settings
        
        has_openai_key = bool(openai_key and len(openai_key.strip()) > 0)
        has_gemini_key = bool(gemini_key and len(gemini_key.strip()) > 0)
        
        # ìƒì„¸ ë¡œê¹…
        logger.info("=" * 60)
        logger.info("API í‚¤ ìƒíƒœ í™•ì¸ (ìƒì„¸)")
        logger.info(f"os.getenv('OPENAI_API_KEY'): {'âœ… ì„¤ì •ë¨' if openai_env else 'âŒ ë¯¸ì„¤ì •'}")
        if openai_env:
            logger.info(f"  - ê¸¸ì´: {len(openai_env)} ë¬¸ì, ì‹œì‘: {openai_env[:10]}...")
        logger.info(f"settings.OPENAI_API_KEY: {'âœ… ì„¤ì •ë¨' if openai_settings else 'âŒ ë¯¸ì„¤ì •'}")
        if openai_settings:
            logger.info(f"  - ê¸¸ì´: {len(openai_settings)} ë¬¸ì, ì‹œì‘: {openai_settings[:10]}...")
        logger.info(f"ìµœì¢… openai_key: {'âœ… ì„¤ì •ë¨' if has_openai_key else 'âŒ ë¯¸ì„¤ì •'}")
        
        logger.info(f"os.getenv('GEMINI_API_KEY'): {'âœ… ì„¤ì •ë¨' if gemini_env else 'âŒ ë¯¸ì„¤ì •'}")
        if gemini_env:
            logger.info(f"  - ê¸¸ì´: {len(gemini_env)} ë¬¸ì, ì‹œì‘: {gemini_env[:10]}...")
        logger.info(f"settings.GEMINI_API_KEY: {'âœ… ì„¤ì •ë¨' if gemini_settings else 'âŒ ë¯¸ì„¤ì •'}")
        if gemini_settings:
            logger.info(f"  - ê¸¸ì´: {len(gemini_settings)} ë¬¸ì, ì‹œì‘: {gemini_settings[:10]}...")
        logger.info(f"ìµœì¢… gemini_key: {'âœ… ì„¤ì •ë¨' if has_gemini_key else 'âŒ ë¯¸ì„¤ì •'}")
        logger.info("=" * 60)
        
        if not has_openai_key and not has_gemini_key:
            logger.error("âš ï¸ AI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤! ê¸°ë³¸ ë¶„ì„ ëª¨ë“œë¡œ ì „í™˜ë©ë‹ˆë‹¤.")
            logger.error("í™˜ê²½ ë³€ìˆ˜ OPENAI_API_KEY ë˜ëŠ” GEMINI_API_KEYë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
            if progress_tracker:
                await progress_tracker.update(100, "AI API í‚¤ ë¯¸ì„¤ì • - ê¸°ë³¸ ë¶„ì„ ëª¨ë“œ")
            return _analyze_basic(target_keyword, target_type, additional_context, start_date, end_date)
        
        # ê¸°ë³¸ì ìœ¼ë¡œ OpenAI API ì‚¬ìš©
        if has_openai_key:
            if progress_tracker:
                await progress_tracker.update(10, "OpenAI APIë¡œ ê¸°ë³¸ ë¶„ì„ ì‹œì‘...")
            logger.info("=" * 60)
            logger.info("ğŸš€ OpenAI API í˜¸ì¶œ ì‹œì‘")
            logger.info(f"API í‚¤ í™•ì¸: âœ… (ê¸¸ì´: {len(openai_key)} ë¬¸ì)")
            logger.info(f"ëª¨ë¸: {settings.OPENAI_MODEL}")
            logger.info("=" * 60)
            try:
                result = await _analyze_with_openai(
                    target_keyword, target_type, additional_context, start_date, end_date, progress_tracker
                )
                logger.info("=" * 60)
                logger.info("âœ… OpenAI API ë¶„ì„ ì„±ê³µ ì™„ë£Œ")
                logger.info(f"ê²°ê³¼ í‚¤: {list(result.keys()) if isinstance(result, dict) else 'N/A'}")
                logger.info("=" * 60)
            except ValueError as ve:
                # API í‚¤ ê´€ë ¨ ì˜¤ë¥˜ëŠ” ì¬ì‹œë„í•˜ì§€ ì•ŠìŒ
                logger.error(f"âŒ OpenAI API í‚¤ ì˜¤ë¥˜: {ve}", exc_info=True)
                raise
            except Exception as e:
                logger.error("=" * 60)
                logger.error(f"âŒ OpenAI API í˜¸ì¶œ ì‹¤íŒ¨: {type(e).__name__}: {e}")
                logger.error(f"ìƒì„¸ ì˜¤ë¥˜: {str(e)}")
                import traceback
                logger.error(f"ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤:\n{traceback.format_exc()}")
                logger.error("=" * 60)
                # OpenAI ì‹¤íŒ¨ ì‹œ Geminië¡œ ì¬ì‹œë„
                if has_gemini_key:
                    logger.info("ğŸ”„ Gemini APIë¡œ ì¬ì‹œë„ ì¤‘...")
                    try:
                        if progress_tracker:
                            await progress_tracker.update(50, "OpenAI ì‹¤íŒ¨, Geminië¡œ ì¬ì‹œë„ ì¤‘...")
                        result = await _analyze_with_gemini(
                            target_keyword, target_type, additional_context, start_date, end_date, progress_tracker
                        )
                        logger.info("âœ… Gemini API ë¶„ì„ ì„±ê³µ (OpenAI ì‹¤íŒ¨ í›„ ì¬ì‹œë„)")
                    except Exception as e2:
                        logger.error(f"âŒ Gemini API ì¬ì‹œë„ë„ ì‹¤íŒ¨: {type(e2).__name__}: {e2}", exc_info=True)
                        logger.error("âš ï¸ ëª¨ë“  AI API í˜¸ì¶œ ì‹¤íŒ¨ - ê¸°ë³¸ ë¶„ì„ ëª¨ë“œë¡œ ì „í™˜")
                        if progress_tracker:
                            await progress_tracker.update(100, "ëª¨ë“  AI API ì‹¤íŒ¨ - ê¸°ë³¸ ë¶„ì„ ëª¨ë“œ")
                        return _analyze_basic(target_keyword, target_type, additional_context, start_date, end_date)
                else:
                    logger.error("âš ï¸ OpenAI ì‹¤íŒ¨ ë° Gemini API í‚¤ ì—†ìŒ - ê¸°ë³¸ ë¶„ì„ ëª¨ë“œë¡œ ì „í™˜")
                    if progress_tracker:
                        await progress_tracker.update(100, "OpenAI ì‹¤íŒ¨, Gemini ì—†ìŒ - ê¸°ë³¸ ë¶„ì„ ëª¨ë“œ")
                    return _analyze_basic(target_keyword, target_type, additional_context, start_date, end_date)
            
            # Gemini APIê°€ ì„ íƒë˜ê³  ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš°, OpenAI ê²°ê³¼ë¥¼ ë³´ì™„
            if use_gemini and has_gemini_key:
                try:
                    if progress_tracker:
                        await progress_tracker.update(60, "Gemini APIë¡œ ê²°ê³¼ ë³´ì™„ ì¤‘...")
                    logger.info("=" * 60)
                    logger.info("ğŸ”„ Gemini APIë¡œ ê²°ê³¼ ë³´ì™„ ì‹œì‘")
                    logger.info("=" * 60)
                    gemini_result = await _analyze_with_gemini(
                        target_keyword, target_type, additional_context, start_date, end_date, progress_tracker
                    )
                    # OpenAIì™€ Gemini ê²°ê³¼ í†µí•©
                    if progress_tracker:
                        await progress_tracker.update(85, "OpenAI + Gemini ê²°ê³¼ í†µí•© ì¤‘...")
                    result = _merge_analysis_results(result, gemini_result, target_type)
                    logger.info("=" * 60)
                    logger.info("âœ… OpenAI + Gemini ê²°ê³¼ í†µí•© ì™„ë£Œ")
                    logger.info("=" * 60)
                except Exception as e:
                    logger.warning("=" * 60)
                    logger.warning(f"âš ï¸ Gemini API ë³´ì™„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ (OpenAI ê²°ê³¼ë§Œ ì‚¬ìš©): {type(e).__name__}: {e}")
                    import traceback
                    logger.warning(f"ìƒì„¸ ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤:\n{traceback.format_exc()}")
                    logger.warning("=" * 60)
                    # Gemini ì‹¤íŒ¨í•´ë„ OpenAI ê²°ê³¼ëŠ” ìœ ì§€
                    if progress_tracker:
                        await progress_tracker.update(90, "Gemini ë³´ì™„ ì‹¤íŒ¨, OpenAI ê²°ê³¼ë§Œ ì‚¬ìš©")
        elif use_gemini and has_gemini_key:
            # OpenAIê°€ ì—†ê³  Geminië§Œ ìˆëŠ” ê²½ìš°
            if progress_tracker:
                await progress_tracker.update(10, "Gemini APIë¡œ ë¶„ì„ ì‹œì‘...")
            logger.info("=" * 60)
            logger.info("ğŸš€ Gemini API í˜¸ì¶œ ì‹œì‘ (OpenAI ì—†ìŒ)")
            logger.info(f"API í‚¤ í™•ì¸: âœ… (ê¸¸ì´: {len(gemini_key)} ë¬¸ì)")
            logger.info("=" * 60)
            try:
                result = await _analyze_with_gemini(
                    target_keyword, target_type, additional_context, start_date, end_date, progress_tracker
                )
                logger.info("=" * 60)
                logger.info("âœ… Gemini API ë¶„ì„ ì„±ê³µ ì™„ë£Œ")
                logger.info(f"ê²°ê³¼ í‚¤: {list(result.keys()) if isinstance(result, dict) else 'N/A'}")
                logger.info("=" * 60)
            except ValueError as ve:
                # API í‚¤ ê´€ë ¨ ì˜¤ë¥˜ëŠ” ì¬ì‹œë„í•˜ì§€ ì•ŠìŒ
                logger.error(f"âŒ Gemini API í‚¤ ì˜¤ë¥˜: {ve}", exc_info=True)
                raise
            except Exception as e:
                logger.error("=" * 60)
                logger.error(f"âŒ Gemini API í˜¸ì¶œ ì‹¤íŒ¨: {type(e).__name__}: {e}")
                import traceback
                logger.error(f"ìƒì„¸ ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤:\n{traceback.format_exc()}")
                logger.error("=" * 60)
                logger.error("âš ï¸ Gemini API ì‹¤íŒ¨ - ê¸°ë³¸ ë¶„ì„ ëª¨ë“œë¡œ ì „í™˜")
                if progress_tracker:
                    await progress_tracker.update(100, "Gemini ì‹¤íŒ¨ - ê¸°ë³¸ ë¶„ì„ ëª¨ë“œ")
                return _analyze_basic(target_keyword, target_type, additional_context, start_date, end_date)
        else:
            # AI APIê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ ë¶„ì„ ìˆ˜í–‰
            logger.warning("âš ï¸ AI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ ê¸°ë³¸ ë¶„ì„ ëª¨ë“œ ì‚¬ìš©")
            logger.warning("í™˜ê²½ ë³€ìˆ˜ OPENAI_API_KEY ë˜ëŠ” GEMINI_API_KEYë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
            if progress_tracker:
                await progress_tracker.update(100, "AI API í‚¤ ë¯¸ì„¤ì • - ê¸°ë³¸ ë¶„ì„ ëª¨ë“œ")
            result = _analyze_basic(target_keyword, target_type, additional_context, start_date, end_date)
        
        logger.info(f"âœ… íƒ€ê²Ÿ ë¶„ì„ ì™„ë£Œ: {target_keyword}")
        return result
        
    except ValueError as ve:
        # API í‚¤ ê´€ë ¨ ì˜¤ë¥˜ëŠ” ê·¸ëŒ€ë¡œ ì „íŒŒ
        logger.error(f"âŒ API í‚¤ ì˜¤ë¥˜: {ve}")
        raise
    except Exception as e:
        logger.error("=" * 60)
        logger.error(f"âŒ íƒ€ê²Ÿ ë¶„ì„ ì¤‘ ì¹˜ëª…ì  ì˜¤ë¥˜: {type(e).__name__}: {e}")
        import traceback
        logger.error(f"ìƒì„¸ ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤:\n{traceback.format_exc()}")
        logger.error("=" * 60)
        # ì˜ˆì™¸ ë°œìƒ ì‹œì—ë„ ê¸°ë³¸ ë¶„ì„ ê²°ê³¼ë¼ë„ ë°˜í™˜
        logger.warning("âš ï¸ ê¸°ë³¸ ë¶„ì„ ëª¨ë“œë¡œ fallback ì‹œë„")
        try:
            return _analyze_basic(target_keyword, target_type, additional_context, start_date, end_date)
        except Exception as e2:
            logger.error(f"âŒ ê¸°ë³¸ ë¶„ì„ ëª¨ë“œë„ ì‹¤íŒ¨: {e2}")
            raise


async def _analyze_with_gemini(
    target_keyword: str,
    target_type: str,
    additional_context: Optional[str],
    start_date: Optional[str] = None,
    end_date: Optional[str] = None,
    progress_tracker: Optional[ProgressTracker] = None
) -> Dict[str, Any]:
    """Gemini APIë¥¼ ì‚¬ìš©í•œ ë¶„ì„"""
    try:
        import asyncio
        
        # API í‚¤ í™•ì¸ (í™˜ê²½ ë³€ìˆ˜ì—ì„œ ì§ì ‘ ì½ê¸° - Vercel í˜¸í™˜ì„±)
        # ì—¬ëŸ¬ ì†ŒìŠ¤ì—ì„œ API í‚¤ í™•ì¸ (ìš°ì„ ìˆœìœ„: í™˜ê²½ ë³€ìˆ˜ > Settings)
        api_key_env = os.getenv('GEMINI_API_KEY')
        api_key_settings = getattr(settings, 'GEMINI_API_KEY', None)
        api_key = api_key_env or api_key_settings
        
        if not api_key or len(api_key.strip()) == 0:
            logger.error(f"GEMINI_API_KEY ë¯¸ì„¤ì • - env: {bool(api_key_env)}, settings: {bool(api_key_settings)}")
            raise ValueError("GEMINI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        logger.info("=" * 60)
        logger.info("ğŸš€ Gemini API í˜¸ì¶œ ì‹œì‘")
        logger.info(f"API í‚¤ í™•ì¸: âœ… (ê¸¸ì´: {len(api_key)} ë¬¸ì)")
        logger.info(f"API í‚¤ ì†ŒìŠ¤: {'í™˜ê²½ ë³€ìˆ˜' if api_key_env else 'Settings'}")
        logger.info(f"ëª¨ë¸: {getattr(settings, 'GEMINI_MODEL', 'gemini-2.5-flash')}")
        logger.info("=" * 60)
        
        # í”„ë¡¬í”„íŠ¸ ìƒì„± ë° ìµœì í™”
        additional_context_optimized = optimize_additional_context(additional_context, max_length=500)
        prompt = _build_analysis_prompt(target_keyword, target_type, additional_context_optimized, start_date, end_date)
        
        # í† í° ìµœì í™” ì ìš©
        prompt_tokens = estimate_tokens(prompt)
        prompt = optimize_prompt(prompt, max_length=8000)  # í”„ë¡¬í”„íŠ¸ ìµœëŒ€ 8000ìë¡œ ì œí•œ
        
        # ëª¨ë¸ ì„¤ì • (ê¸°ë³¸ê°’: gemini-2.5-flash)
        model_name = getattr(settings, 'GEMINI_MODEL', 'gemini-2.5-flash')
        logger.info(f"Gemini API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì¤‘... (ëª¨ë¸: {model_name})")
        logger.info(f"í”„ë¡¬í”„íŠ¸ í† í° ì¶”ì •: {prompt_tokens}, ìµœì í™” í›„ ê¸¸ì´: {len(prompt)} ë¬¸ì")
        
        # ìƒˆë¡œìš´ Gemini API ë°©ì‹ ì‹œë„ (from google import genai)
        try:
            from google import genai
            
            # API í‚¤ ì„¤ì • (í™˜ê²½ ë³€ìˆ˜ ë˜ëŠ” ì„¤ì •ì—ì„œ)
            api_key = settings.GEMINI_API_KEY or os.getenv('GEMINI_API_KEY')
            if api_key:
                client = genai.Client(api_key=api_key)
            else:
                # í™˜ê²½ ë³€ìˆ˜ì—ì„œ ìë™ìœ¼ë¡œ ê°€ì ¸ì˜¤ê¸°
                client = genai.Client()
            
            # ì‹œìŠ¤í…œ ë©”ì‹œì§€ì™€ í”„ë¡¬í”„íŠ¸ ê²°í•© (ìµœì í™”)
            system_message = _build_system_message(target_type)
            system_message = optimize_prompt(system_message, max_length=500)  # ì‹œìŠ¤í…œ ë©”ì‹œì§€ë„ ìµœì í™”
            full_prompt = f"{system_message}\n\n{prompt}\n\nJSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”."
            
            # í† í° ìˆ˜ ê³„ì‚° ë° max_tokens ì„¤ì •
            full_prompt_tokens = estimate_tokens(full_prompt)
            max_output_tokens = get_max_tokens_for_model(model_name, full_prompt_tokens)
            
            # API í˜¸ì¶œ (ë¹„ë™ê¸° ì‹¤í–‰ì„ ìœ„í•´ run_in_executor ì‚¬ìš©)
            logger.info("=" * 60)
            logger.info("ğŸ“¡ Gemini API ìš”ì²­ ì „ì†¡ ì¤‘...")
            logger.info(f"ëª¨ë¸: {model_name}")
            logger.info(f"í”„ë¡¬í”„íŠ¸ ê¸¸ì´: {len(full_prompt)} ë¬¸ì")
            logger.info(f"í”„ë¡¬í”„íŠ¸ í† í° ì¶”ì •: {full_prompt_tokens}")
            logger.info(f"ìµœëŒ€ ì¶œë ¥ í† í°: {max_output_tokens}")
            logger.info("=" * 60)
            loop = asyncio.get_event_loop()
            try:
                # JSON ì‘ë‹µ ê°•ì œ ì‹œë„ (ìƒˆë¡œìš´ API ë°©ì‹)
                # config íŒŒë¼ë¯¸í„°ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ì „ë‹¬
                try:
                    # max_output_tokens ì„¤ì • ì¶”ê°€
                    response = await loop.run_in_executor(
                        None, 
                        lambda: client.models.generate_content(
                            model=model_name,
                            contents=full_prompt,
                            config={
                                "response_mime_type": "application/json",
                                "max_output_tokens": max_output_tokens
                            }
                        )
                    )
                    logger.info("=" * 60)
                    logger.info("âœ… Gemini API ì‘ë‹µ ìˆ˜ì‹  ì™„ë£Œ (JSON ëª¨ë“œ)")
                    logger.info("=" * 60)
                except (TypeError, AttributeError) as config_error:
                    # config íŒŒë¼ë¯¸í„°ê°€ ì§€ì›ë˜ì§€ ì•ŠëŠ” ê²½ìš° generation_config ì‹œë„
                    logger.warning(f"config íŒŒë¼ë¯¸í„° ë¯¸ì§€ì›, generation_config ì‹œë„: {config_error}")
                    try:
                        response = await loop.run_in_executor(
                            None, 
                            lambda: client.models.generate_content(
                                model=model_name,
                                contents=full_prompt,
                                generation_config={
                                    "response_mime_type": "application/json",
                                    "max_output_tokens": max_output_tokens
                                }
                            )
                        )
                        logger.info("âœ… Gemini API ì‘ë‹µ ìˆ˜ì‹  ì™„ë£Œ (generation_config ì‚¬ìš©)")
                    except Exception as gen_error:
                        # generation_configë„ ì‹¤íŒ¨í•˜ë©´ ì¼ë°˜ ëª¨ë“œ
                        logger.warning(f"generation_configë„ ì‹¤íŒ¨, ì¼ë°˜ ëª¨ë“œë¡œ ì¬ì‹œë„: {gen_error}")
                        response = await loop.run_in_executor(
                            None, 
                            lambda: client.models.generate_content(
                                model=model_name,
                                contents=full_prompt,
                                config={
                                    "max_output_tokens": max_output_tokens
                                }
                            )
                        )
                        logger.info("âœ… Gemini API ì‘ë‹µ ìˆ˜ì‹  ì™„ë£Œ (ì¼ë°˜ ëª¨ë“œ)")
            except Exception as e:
                logger.warning("=" * 60)
                logger.warning(f"âš ï¸ JSON ì‘ë‹µ ê°•ì œ ì‹¤íŒ¨, ì¼ë°˜ ëª¨ë“œë¡œ ì¬ì‹œë„: {type(e).__name__}: {e}")
                logger.warning("=" * 60)
                # JSON ì‘ë‹µ ê°•ì œê°€ ì‹¤íŒ¨í•˜ë©´ ì¼ë°˜ ëª¨ë“œë¡œ ì¬ì‹œë„
                try:
                    response = await loop.run_in_executor(
                        None, 
                        lambda: client.models.generate_content(
                            model=model_name,
                            contents=full_prompt
                        )
                    )
                    logger.info("âœ… ì¼ë°˜ ëª¨ë“œë¡œ Gemini API ì‘ë‹µ ìˆ˜ì‹  ì™„ë£Œ")
                except Exception as e2:
                    logger.error("=" * 60)
                    logger.error(f"âŒ Gemini API ì¼ë°˜ ëª¨ë“œë„ ì‹¤íŒ¨: {type(e2).__name__}: {e2}")
                    import traceback
                    logger.error(f"ìƒì„¸ ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤:\n{traceback.format_exc()}")
                    logger.error("=" * 60)
                    raise ValueError(f"Gemini API í˜¸ì¶œ ì‹¤íŒ¨: {str(e2)}")
            
            # ì‘ë‹µ íŒŒì‹±
            result_text = response.text if hasattr(response, 'text') else str(response)
            logger.info(f"Gemini ì‘ë‹µ ê¸¸ì´: {len(result_text)} ë¬¸ì")
            
        except ImportError:
            # ìƒˆë¡œìš´ ë°©ì‹ì´ ì—†ìœ¼ë©´ ê¸°ì¡´ ë°©ì‹ ì‹œë„
            import google.generativeai as genai_old
            
            genai_old.configure(api_key=settings.GEMINI_API_KEY or os.getenv('GEMINI_API_KEY'))
            model = genai_old.GenerativeModel(model_name)
            
            # ì‹œìŠ¤í…œ ë©”ì‹œì§€ì™€ í”„ë¡¬í”„íŠ¸ ê²°í•© (ìµœì í™”)
            system_message = _build_system_message(target_type)
            system_message = optimize_prompt(system_message, max_length=500)
            full_prompt = f"{system_message}\n\n{prompt}\n\nJSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”."
            
            # í† í° ìˆ˜ ê³„ì‚°
            full_prompt_tokens = estimate_tokens(full_prompt)
            max_output_tokens = get_max_tokens_for_model(model_name, full_prompt_tokens)
            
            # API í˜¸ì¶œ (ë¹„ë™ê¸° ì‹¤í–‰ì„ ìœ„í•´ run_in_executor ì‚¬ìš©)
            loop = asyncio.get_event_loop()
            try:
                # JSON ì‘ë‹µ ê°•ì œ ì‹œë„ (ê¸°ì¡´ API ë°©ì‹)
                # google.generativeaiì—ì„œëŠ” generation_config ì‚¬ìš©
                try:
                    # GenerationConfig ê°ì²´ ì‚¬ìš© ì‹œë„
                    response = await loop.run_in_executor(
                        None, 
                        lambda: model.generate_content(
                            full_prompt,
                            generation_config=genai_old.types.GenerationConfig(
                                response_mime_type="application/json",
                                max_output_tokens=max_output_tokens
                            )
                        )
                    )
                except (AttributeError, TypeError):
                    # GenerationConfigê°€ ì—†ê±°ë‚˜ ì§€ì›í•˜ì§€ ì•ŠëŠ” ê²½ìš° ë”•ì…”ë„ˆë¦¬ ì‚¬ìš©
                    response = await loop.run_in_executor(
                        None, 
                        lambda: model.generate_content(
                            full_prompt,
                            generation_config={
                                "response_mime_type": "application/json",
                                "max_output_tokens": max_output_tokens
                            }
                        )
                    )
                logger.info("âœ… JSON ëª¨ë“œë¡œ Gemini API ì‘ë‹µ ìˆ˜ì‹  ì™„ë£Œ")
            except Exception as e:
                logger.warning("=" * 60)
                logger.warning(f"âš ï¸ JSON ì‘ë‹µ ê°•ì œ ì‹¤íŒ¨, ì¼ë°˜ ëª¨ë“œë¡œ ì¬ì‹œë„: {type(e).__name__}: {e}")
                logger.warning("=" * 60)
                # JSON ì‘ë‹µ ê°•ì œê°€ ì‹¤íŒ¨í•˜ë©´ ì¼ë°˜ ëª¨ë“œë¡œ ì¬ì‹œë„
                try:
                    response = await loop.run_in_executor(
                        None, 
                        lambda: model.generate_content(full_prompt)
                    )
                    logger.info("âœ… ì¼ë°˜ ëª¨ë“œë¡œ Gemini API ì‘ë‹µ ìˆ˜ì‹  ì™„ë£Œ")
                except Exception as e2:
                    logger.error("=" * 60)
                    logger.error(f"âŒ Gemini API ì¼ë°˜ ëª¨ë“œë„ ì‹¤íŒ¨: {type(e2).__name__}: {e2}")
                    import traceback
                    logger.error(f"ìƒì„¸ ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤:\n{traceback.format_exc()}")
                    logger.error("=" * 60)
                    raise ValueError(f"Gemini API í˜¸ì¶œ ì‹¤íŒ¨: {str(e2)}")
            
            # ì‘ë‹µ íŒŒì‹±
            result_text = response.text if hasattr(response, 'text') else str(response)
            logger.info(f"Gemini ì‘ë‹µ ê¸¸ì´: {len(result_text)} ë¬¸ì (ê¸°ì¡´ ë°©ì‹)")
        
        if progress_tracker:
            await progress_tracker.update(80, "AI ì‘ë‹µ ìˆ˜ì‹  ì™„ë£Œ, ê²°ê³¼ íŒŒì‹± ì¤‘...")
        
        # JSON í˜•ì‹ìœ¼ë¡œ íŒŒì‹± ì‹œë„
        if not result_text:
            raise ValueError("Gemini API ì‘ë‹µì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
        
        # ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±°
        clean_text = result_text.strip()
        if clean_text.startswith("```json"):
            clean_text = clean_text[7:]  # ```json ì œê±°
        if clean_text.startswith("```"):
            clean_text = clean_text[3:]  # ``` ì œê±°
        if clean_text.endswith("```"):
            clean_text = clean_text[:-3]  # ëì˜ ``` ì œê±°
        clean_text = clean_text.strip()
        
        try:
            result = json.loads(clean_text)
        except json.JSONDecodeError as e:
            logger.warning(f"JSON íŒŒì‹± ì‹¤íŒ¨, ì¬ì‹œë„: {e}")
            logger.warning(f"ì‹¤íŒ¨ ìœ„ì¹˜: line {e.lineno}, column {e.colno}, char {e.pos}")
            # í•œ ë²ˆ ë” ì‹œë„: ì¤‘ê´„í˜¸ë§Œ ì¶”ì¶œ
            try:
                start_idx = clean_text.find("{")
                end_idx = clean_text.rfind("}") + 1
                if start_idx >= 0 and end_idx > start_idx:
                    # ì¤‘ê´„í˜¸ ì‚¬ì´ì˜ í…ìŠ¤íŠ¸ ì¶”ì¶œ
                    json_text = clean_text[start_idx:end_idx]
                    # ë§ˆì§€ë§‰ ì‰¼í‘œ ì œê±° ì‹œë„ (ì˜ëª»ëœ JSON í˜•ì‹ ìˆ˜ì •)
                    json_text = json_text.rstrip().rstrip(',')
                    # ë‹«ëŠ” ì¤‘ê´„í˜¸ ë‹¤ì‹œ ì¶”ê°€
                    if not json_text.endswith("}"):
                        json_text += "}"
                    result = json.loads(json_text)
                    logger.info("âœ… ì¤‘ê´„í˜¸ ì¶”ì¶œ í›„ JSON íŒŒì‹± ì„±ê³µ")
                else:
                    raise ValueError("ìœ íš¨í•œ JSONì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            except Exception as e2:
                logger.error(f"JSON íŒŒì‹± ìµœì¢… ì‹¤íŒ¨: {e2}")
                logger.error(f"ì›ë³¸ í…ìŠ¤íŠ¸ (ì²˜ìŒ 500ì): {clean_text[:500]}")
                logger.error(f"ì›ë³¸ í…ìŠ¤íŠ¸ (ë§ˆì§€ë§‰ 500ì): {clean_text[-500:]}")
                # JSONì´ ì•„ë‹ˆë©´ í…ìŠ¤íŠ¸ë¡œ ë°˜í™˜í•˜ë˜, ê°€ëŠ¥í•œ ë¶€ë¶„ë§Œ ì¶”ì¶œ
                try:
                    # ìµœì†Œí•œì˜ êµ¬ì¡°ë¼ë„ ì¶”ì¶œ ì‹œë„
                    if "executive_summary" in clean_text:
                        # ë¶€ë¶„ íŒŒì‹± ì‹œë„
                        import re
                        exec_match = re.search(r'"executive_summary"\s*:\s*"([^"]+)"', clean_text)
                        exec_summary = exec_match.group(1) if exec_match else f"{target_keyword}ì— ëŒ€í•œ {target_type} ë¶„ì„ì„ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤."
                    else:
                        exec_summary = f"{target_keyword}ì— ëŒ€í•œ {target_type} ë¶„ì„ì„ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤."
                except:
                    exec_summary = f"{target_keyword}ì— ëŒ€í•œ {target_type} ë¶„ì„ì„ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤."
                
                result = {
                    "executive_summary": exec_summary,
                    "key_findings": {
                        "primary_insights": [
                            "AI ì‘ë‹µ íŒŒì‹±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.",
                            "ì›ë³¸ ì‘ë‹µì„ í™•ì¸í•˜ì„¸ìš”.",
                            f"ì˜¤ë¥˜: {str(e2)[:200]}"
                        ],
                        "quantitative_metrics": {}
                    },
                    "detailed_analysis": {
                        "insights": {
                            "raw_response": result_text[:1000] if len(result_text) > 1000 else result_text  # ì²˜ìŒ 1000ì
                        }
                    },
                    "strategic_recommendations": {
                        "immediate_actions": [
                            "ì„œë²„ ë¡œê·¸ë¥¼ í™•ì¸í•˜ì—¬ AI ì‘ë‹µì„ ê²€í† í•˜ì„¸ìš”.",
                            "í”„ë¡¬í”„íŠ¸ë¥¼ ì¡°ì •í•˜ì—¬ JSON í˜•ì‹ ì‘ë‹µì„ ê°•ì œí•˜ì„¸ìš”."
                        ]
                    },
                    "target_keyword": target_keyword,
                    "target_type": target_type,
                    "error": "JSON íŒŒì‹± ì‹¤íŒ¨",
                    "raw_response_length": len(result_text)
                }
        
        # ê²°ê³¼ì— ë©”íƒ€ë°ì´í„° ì¶”ê°€ (ì—†ëŠ” ê²½ìš°ì—ë§Œ)
        if "target_keyword" not in result:
            result["target_keyword"] = target_keyword
        if "target_type" not in result:
            result["target_type"] = target_type
        
        return result
        
    except ImportError as e:
        logger.error("=" * 60)
        logger.error(f"âŒ Gemini API íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {e}")
        logger.error("'pip install google-genai' ë˜ëŠ” 'pip install google-generativeai'ë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
        logger.error("=" * 60)
        raise ValueError(f"Gemini API íŒ¨í‚¤ì§€ ë¯¸ì„¤ì¹˜: {e}")
    except ValueError as ve:
        # API í‚¤ ê´€ë ¨ ì˜¤ë¥˜ëŠ” ê·¸ëŒ€ë¡œ ì „íŒŒ
        raise
    except Exception as e:
        logger.error("=" * 60)
        logger.error(f"âŒ Gemini API í˜¸ì¶œ ì‹¤íŒ¨: {type(e).__name__}: {e}")
        import traceback
        logger.error(f"ìƒì„¸ ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤:\n{traceback.format_exc()}")
        logger.error("=" * 60)
        raise ValueError(f"Gemini API í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}")


async def _analyze_with_openai(
    target_keyword: str,
    target_type: str,
    additional_context: Optional[str],
    start_date: Optional[str] = None,
    end_date: Optional[str] = None,
    progress_tracker: Optional[ProgressTracker] = None
) -> Dict[str, Any]:
    """OpenAI APIë¥¼ ì‚¬ìš©í•œ ë¶„ì„"""
    try:
        from openai import AsyncOpenAI
        
        # API í‚¤ í™•ì¸ (í™˜ê²½ ë³€ìˆ˜ì—ì„œ ì§ì ‘ ì½ê¸° - Vercel í˜¸í™˜ì„±)
        # ì—¬ëŸ¬ ì†ŒìŠ¤ì—ì„œ API í‚¤ í™•ì¸ (ìš°ì„ ìˆœìœ„: í™˜ê²½ ë³€ìˆ˜ > Settings)
        api_key_env = os.getenv('OPENAI_API_KEY')
        api_key_settings = getattr(settings, 'OPENAI_API_KEY', None)
        api_key = api_key_env or api_key_settings
        
        if not api_key or len(api_key.strip()) == 0:
            logger.error(f"OPENAI_API_KEY ë¯¸ì„¤ì • - env: {bool(api_key_env)}, settings: {bool(api_key_settings)}")
            raise ValueError("OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        logger.info(f"OpenAI API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì¤‘... (ëª¨ë¸: {settings.OPENAI_MODEL})")
        logger.info(f"API í‚¤ ì†ŒìŠ¤: {'í™˜ê²½ ë³€ìˆ˜' if api_key_env else 'Settings'}, ê¸¸ì´: {len(api_key)} ë¬¸ì")
        client = AsyncOpenAI(api_key=api_key)
        
        # í”„ë¡¬í”„íŠ¸ ìƒì„± ë° ìµœì í™”
        if progress_tracker:
            await progress_tracker.update(20, "í”„ë¡¬í”„íŠ¸ ìƒì„± ì¤‘...")
        additional_context_optimized = optimize_additional_context(additional_context, max_length=500)
        prompt = _build_analysis_prompt(target_keyword, target_type, additional_context_optimized, start_date, end_date)
        
        # í† í° ìµœì í™” ì ìš©
        prompt_tokens = estimate_tokens(prompt)
        prompt = optimize_prompt(prompt, max_length=8000)  # í”„ë¡¬í”„íŠ¸ ìµœëŒ€ 8000ìë¡œ ì œí•œ
        
        # ì‹œìŠ¤í…œ ë©”ì‹œì§€ ìƒì„± ë° ìµœì í™”
        system_message = _build_system_message(target_type)
        system_message = optimize_prompt(system_message, max_length=500)
        
        # í† í° ìˆ˜ ê³„ì‚° ë° max_tokens ì„¤ì •
        full_prompt_tokens = estimate_tokens(system_message) + prompt_tokens
        max_output_tokens = get_max_tokens_for_model(settings.OPENAI_MODEL, full_prompt_tokens)
        
        if progress_tracker:
            await progress_tracker.update(30, "OpenAI API ìš”ì²­ ì „ì†¡ ì¤‘...")
        
        # API í˜¸ì¶œ
        logger.info("=" * 60)
        logger.info("ğŸ“¡ OpenAI API ìš”ì²­ ì „ì†¡ ì¤‘...")
        logger.info(f"ëª¨ë¸: {settings.OPENAI_MODEL}")
        logger.info(f"í”„ë¡¬í”„íŠ¸ ê¸¸ì´: {len(prompt)} ë¬¸ì")
        logger.info(f"í”„ë¡¬í”„íŠ¸ í† í° ì¶”ì •: {full_prompt_tokens}")
        logger.info(f"ìµœëŒ€ ì¶œë ¥ í† í°: {max_output_tokens}")
        logger.info("=" * 60)
        try:
            response = await client.chat.completions.create(
                model=settings.OPENAI_MODEL,
                messages=[
                    {"role": "system", "content": system_message},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=max_output_tokens,  # ìµœëŒ€ ì¶œë ¥ í† í° ì„¤ì •
                response_format={"type": "json_object"}  # JSON ì‘ë‹µ ê°•ì œ
            )
            logger.info("=" * 60)
            logger.info("âœ… OpenAI API ì‘ë‹µ ìˆ˜ì‹  ì™„ë£Œ")
            logger.info(f"ì‘ë‹µ ID: {response.id if hasattr(response, 'id') else 'N/A'}")
            logger.info(f"ì‚¬ìš©ëœ í† í°: {response.usage.total_tokens if hasattr(response, 'usage') else 'N/A'}")
            logger.info("=" * 60)
        except Exception as api_error:
            logger.error("=" * 60)
            logger.error(f"âŒ OpenAI API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {type(api_error).__name__}: {api_error}")
            import traceback
            logger.error(f"ìƒì„¸ ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤:\n{traceback.format_exc()}")
            logger.error("=" * 60)
            raise ValueError(f"OpenAI API í˜¸ì¶œ ì‹¤íŒ¨: {str(api_error)}")
        
        result_text = response.choices[0].message.content
        
        if not result_text:
            raise ValueError("OpenAI API ì‘ë‹µì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
        
        logger.info(f"OpenAI ì‘ë‹µ ê¸¸ì´: {len(result_text)} ë¬¸ì")
        
        if progress_tracker:
            await progress_tracker.update(80, "AI ì‘ë‹µ ìˆ˜ì‹  ì™„ë£Œ, ê²°ê³¼ íŒŒì‹± ì¤‘...")
        
        # JSON í˜•ì‹ìœ¼ë¡œ íŒŒì‹± ì‹œë„
        try:
            # result_textê°€ ë¬¸ìì—´ì¸ì§€ í™•ì¸
            if isinstance(result_text, str):
                # ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±°
                clean_text = result_text.strip()
                if clean_text.startswith("```json"):
                    clean_text = clean_text[7:]  # ```json ì œê±°
                if clean_text.startswith("```"):
                    clean_text = clean_text[3:]  # ``` ì œê±°
                if clean_text.endswith("```"):
                    clean_text = clean_text[:-3]  # ëì˜ ``` ì œê±°
                clean_text = clean_text.strip()
                
                result = json.loads(clean_text)
                if progress_tracker:
                    await progress_tracker.update(90, "JSON íŒŒì‹± ì™„ë£Œ, ê²°ê³¼ ì •ë¦¬ ì¤‘...")
            else:
                # ë¬¸ìì—´ ì‘ë‹µì¸ ê²½ìš°
                result = {
                    "executive_summary": f"{target_keyword}ì— ëŒ€í•œ {target_type} ë¶„ì„ì„ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤.",
                    "key_findings": {
                        "primary_insights": [
                            "AI ì‘ë‹µì´ ë¬¸ìì—´ í˜•ì‹ìœ¼ë¡œ ë°˜í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.",
                            "JSON í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                        ],
                        "quantitative_metrics": {}
                    },
                    "detailed_analysis": {
                        "insights": {
                            "raw_response": str(result_text)[:500]  # ì²˜ìŒ 500ìë§Œ
                        }
                    },
                    "strategic_recommendations": {
                        "immediate_actions": [
                            "AI ì‘ë‹µ í˜•ì‹ì„ í™•ì¸í•˜ì„¸ìš”.",
                            "JSON í˜•ì‹ ì‘ë‹µì„ ê°•ì œí•˜ë„ë¡ í”„ë¡¬í”„íŠ¸ë¥¼ ìˆ˜ì •í•˜ì„¸ìš”."
                        ]
                    },
                    "target_keyword": target_keyword,
                    "target_type": target_type
                }
        except json.JSONDecodeError as e:
            logger.warning(f"JSON íŒŒì‹± ì‹¤íŒ¨, ì¬ì‹œë„: {e}")
            # í•œ ë²ˆ ë” ì‹œë„: ì¤‘ê´„í˜¸ë§Œ ì¶”ì¶œ
            try:
                if isinstance(result_text, str):
                    clean_text = result_text.strip()
                    start_idx = clean_text.find("{")
                    end_idx = clean_text.rfind("}") + 1
                    if start_idx >= 0 and end_idx > start_idx:
                        result = json.loads(clean_text[start_idx:end_idx])
                    else:
                        raise ValueError("ìœ íš¨í•œ JSONì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    raise ValueError("ì‘ë‹µì´ ë¬¸ìì—´ì´ ì•„ë‹™ë‹ˆë‹¤.")
            except Exception as e2:
                logger.error(f"JSON íŒŒì‹± ìµœì¢… ì‹¤íŒ¨: {e2}")
                # JSONì´ ì•„ë‹ˆë©´ êµ¬ì¡°í™”ëœ ì˜¤ë¥˜ ì‘ë‹µ ë°˜í™˜
                result = {
                    "executive_summary": f"{target_keyword}ì— ëŒ€í•œ {target_type} ë¶„ì„ì„ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤.",
                    "key_findings": {
                        "primary_insights": [
                            "AI ì‘ë‹µ íŒŒì‹±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.",
                            "ì›ë³¸ ì‘ë‹µì„ í™•ì¸í•˜ì„¸ìš”."
                        ],
                        "quantitative_metrics": {}
                    },
                    "detailed_analysis": {
                        "insights": {
                            "raw_response": str(result_text)[:500] if isinstance(result_text, str) else str(result_text)
                        }
                    },
                    "strategic_recommendations": {
                        "immediate_actions": [
                            "ì„œë²„ ë¡œê·¸ë¥¼ í™•ì¸í•˜ì—¬ AI ì‘ë‹µì„ ê²€í† í•˜ì„¸ìš”.",
                            "í”„ë¡¬í”„íŠ¸ë¥¼ ì¡°ì •í•˜ì—¬ JSON í˜•ì‹ ì‘ë‹µì„ ê°•ì œí•˜ì„¸ìš”."
                        ]
                    },
                    "target_keyword": target_keyword,
                    "target_type": target_type,
                    "error": "JSON íŒŒì‹± ì‹¤íŒ¨"
                }
        
        # ê²°ê³¼ì— ë©”íƒ€ë°ì´í„° ì¶”ê°€ (ì—†ëŠ” ê²½ìš°ì—ë§Œ)
        if "target_keyword" not in result:
            result["target_keyword"] = target_keyword
        if "target_type" not in result:
            result["target_type"] = target_type
        
        return result
        
    except ImportError as ie:
        logger.error("=" * 60)
        logger.error(f"âŒ OpenAI íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {ie}")
        logger.error("'pip install openai'ë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
        logger.error("=" * 60)
        raise ValueError(f"OpenAI íŒ¨í‚¤ì§€ ë¯¸ì„¤ì¹˜: {ie}")
    except ValueError as ve:
        # API í‚¤ ê´€ë ¨ ì˜¤ë¥˜ëŠ” ê·¸ëŒ€ë¡œ ì „íŒŒ
        raise
    except Exception as e:
        logger.error("=" * 60)
        logger.error(f"âŒ OpenAI API í˜¸ì¶œ ì‹¤íŒ¨: {type(e).__name__}: {e}")
        import traceback
        logger.error(f"ìƒì„¸ ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤:\n{traceback.format_exc()}")
        logger.error("=" * 60)
        raise ValueError(f"OpenAI API í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}")


def _analyze_basic(
    target_keyword: str,
    target_type: str,
    additional_context: Optional[str],
    start_date: Optional[str] = None,
    end_date: Optional[str] = None
) -> Dict[str, Any]:
    """ê¸°ë³¸ ë¶„ì„ (AI API ì—†ì´)"""
    logger.info("ê¸°ë³¸ ë¶„ì„ ëª¨ë“œ ì‚¬ìš©")
    
    period_note = ""
    if start_date and end_date:
        period_note = f" (ë¶„ì„ ê¸°ê°„: {start_date} ~ {end_date})"
    elif start_date:
        period_note = f" (ì‹œì‘ì¼: {start_date})"
    elif end_date:
        period_note = f" (ì¢…ë£Œì¼: {end_date})"
    
    # MECE êµ¬ì¡°ë¡œ ê¸°ë³¸ ë¶„ì„ ê²°ê³¼ ë°˜í™˜
    # API í‚¤ ìƒíƒœ í™•ì¸ (í™˜ê²½ ë³€ìˆ˜ì—ì„œ ì§ì ‘ í™•ì¸ - Vercel í˜¸í™˜ì„±)
    openai_env = os.getenv('OPENAI_API_KEY')
    gemini_env = os.getenv('GEMINI_API_KEY')
    openai_settings = getattr(settings, 'OPENAI_API_KEY', None)
    gemini_settings = getattr(settings, 'GEMINI_API_KEY', None)
    
    openai_key = openai_env or openai_settings
    gemini_key = gemini_env or gemini_settings
    
    has_openai = bool(openai_key and len(openai_key.strip()) > 0)
    has_gemini = bool(gemini_key and len(gemini_key.strip()) > 0)
    
    api_key_status = {
        "openai_configured": has_openai,
        "gemini_configured": has_gemini,
        "message": "âš ï¸ AI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ ê¸°ë³¸ ë¶„ì„ ëª¨ë“œë¡œ ì‹¤í–‰ë˜ì—ˆìŠµë‹ˆë‹¤."
    }
    
    if not api_key_status["openai_configured"] and not api_key_status["gemini_configured"]:
        api_key_status["message"] = "âŒ OpenAI API í‚¤ì™€ Gemini API í‚¤ê°€ ëª¨ë‘ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í™˜ê²½ ë³€ìˆ˜ OPENAI_API_KEY ë˜ëŠ” GEMINI_API_KEYë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”."
    elif not api_key_status["openai_configured"]:
        api_key_status["message"] = "âš ï¸ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í™˜ê²½ ë³€ìˆ˜ OPENAI_API_KEYë¥¼ ì„¤ì •í•˜ë©´ ë” ì •í™•í•œ ë¶„ì„ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤."
    elif not api_key_status["gemini_configured"]:
        api_key_status["message"] = "â„¹ï¸ Gemini API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í™˜ê²½ ë³€ìˆ˜ GEMINI_API_KEYë¥¼ ì„¤ì •í•˜ë©´ ë³´ì™„ ë¶„ì„ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤."
    
    result = {
        "target_keyword": target_keyword,
        "target_type": target_type,
        "api_key_status": api_key_status,
        "executive_summary": f"{target_keyword}ì— ëŒ€í•œ {target_type} ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤.{period_note}\n\n{api_key_status['message']}\n\nAI APIë¥¼ ì„¤ì •í•˜ë©´ ë” ìƒì„¸í•˜ê³  ì •í™•í•œ ë¶„ì„ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.",
        "key_findings": {
            "primary_insights": [
                f"{target_keyword}ì˜ ì£¼ìš” íŠ¹ì§•",
                f"{target_type} ê´€ì ì—ì„œì˜ ë¶„ì„",
                "ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸ê°€ ì œê³µëœ ê²½ìš° ì´ë¥¼ ë°˜ì˜í•œ ë¶„ì„",
                "âš ï¸ ì´ ê²°ê³¼ëŠ” ê¸°ë³¸ ë¶„ì„ ëª¨ë“œì…ë‹ˆë‹¤. AI API í‚¤ë¥¼ ì„¤ì •í•˜ë©´ í›¨ì”¬ ë” ìƒì„¸í•œ ë¶„ì„ì„ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
            ],
            "quantitative_metrics": {
                "estimated_volume": "AI API í•„ìš” - OpenAI ë˜ëŠ” Gemini API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”",
                "competition_level": "AI API í•„ìš” - OpenAI ë˜ëŠ” Gemini API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”",
                "growth_potential": "AI API í•„ìš” - OpenAI ë˜ëŠ” Gemini API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”"
            }
        },
        "detailed_analysis": {
            "insights": {
                "note": api_key_status["message"],
                "setup_instructions": {
                    "openai": "í™˜ê²½ ë³€ìˆ˜ì— OPENAI_API_KEYë¥¼ ì„¤ì •í•˜ì„¸ìš”. ì˜ˆ: export OPENAI_API_KEY='sk-...'",
                    "gemini": "í™˜ê²½ ë³€ìˆ˜ì— GEMINI_API_KEYë¥¼ ì„¤ì •í•˜ì„¸ìš”. ì˜ˆ: export GEMINI_API_KEY='...'",
                    "vercel": "Vercel ë°°í¬ ì‹œ í™˜ê²½ ë³€ìˆ˜ëŠ” Vercel ëŒ€ì‹œë³´ë“œì˜ Settings > Environment Variablesì—ì„œ ì„¤ì •í•˜ì„¸ìš”."
                }
            }
        },
        "strategic_recommendations": {
            "immediate_actions": [
                "OpenAI ë˜ëŠ” Gemini API í‚¤ë¥¼ í™˜ê²½ ë³€ìˆ˜ì— ì„¤ì •í•´ì£¼ì„¸ìš”.",
                "API í‚¤ ì„¤ì • í›„ ì„œë²„ë¥¼ ì¬ì‹œì‘í•˜ê³  ë‹¤ì‹œ ë¶„ì„ì„ ì‹œë„í•˜ì„¸ìš”.",
                "Vercel ë°°í¬ ì‹œ: Vercel ëŒ€ì‹œë³´ë“œ > Settings > Environment Variablesì—ì„œ ì„¤ì •",
                "ë¡œì»¬ ê°œë°œ ì‹œ: .env íŒŒì¼ì— OPENAI_API_KEY ë˜ëŠ” GEMINI_API_KEY ì¶”ê°€"
            ],
            "short_term_strategies": [
                "AI APIë¥¼ í†µí•œ ì •ëŸ‰ì  ë°ì´í„° ìˆ˜ì§‘",
                "ì •ì„±ì  ì¸ì‚¬ì´íŠ¸ ë„ì¶œ",
                "ê¸°ê°„ë³„ íŠ¸ë Œë“œ ë¶„ì„"
            ],
            "long_term_strategies": [
                "ì§€ì†ì ì¸ ë°ì´í„° ëª¨ë‹ˆí„°ë§",
                "íŠ¸ë Œë“œ ë¶„ì„ ë° ì˜ˆì¸¡",
                "ìë™í™”ëœ ë¶„ì„ íŒŒì´í”„ë¼ì¸ êµ¬ì¶•"
            ]
        },
        # í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•œ ê¸°ì¡´ êµ¬ì¡°ë„ í¬í•¨
        "analysis": {
            "summary": f"{target_keyword}ì— ëŒ€í•œ {target_type} ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤.{period_note}",
            "key_points": [
                f"{target_keyword}ì˜ ì£¼ìš” íŠ¹ì§•",
                f"{target_type} ê´€ì ì—ì„œì˜ ë¶„ì„",
                "ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸ê°€ ì œê³µëœ ê²½ìš° ì´ë¥¼ ë°˜ì˜í•œ ë¶„ì„"
            ],
            "recommendations": [
                "AI APIë¥¼ ì„¤ì •í•˜ë©´ ë” ìƒì„¸í•œ ë¶„ì„ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.",
                "OpenAI ë˜ëŠ” Gemini API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”."
            ]
        }
    }
    
    if additional_context:
        result["additional_context"] = additional_context
        if isinstance(result["analysis"], dict):
            result["analysis"]["context_applied"] = True
    
    if start_date or end_date:
        result["analysis"]["period"] = {
            "start_date": start_date,
            "end_date": end_date
        }
    
    return result


def _merge_analysis_results(openai_result: Dict[str, Any], gemini_result: Dict[str, Any], target_type: str) -> Dict[str, Any]:
    """
    OpenAIì™€ Gemini ë¶„ì„ ê²°ê³¼ë¥¼ í†µí•©í•©ë‹ˆë‹¤.
    OpenAI ê²°ê³¼ë¥¼ ê¸°ë³¸ìœ¼ë¡œ í•˜ê³ , Gemini ê²°ê³¼ë¡œ ë³´ì™„í•©ë‹ˆë‹¤.
    """
    merged = openai_result.copy()
    
    # Executive Summary í†µí•©
    if gemini_result.get("executive_summary") and openai_result.get("executive_summary"):
        # ë‘ ìš”ì•½ì„ ê²°í•©
        merged["executive_summary"] = (
            f"{openai_result['executive_summary']}\n\n"
            f"**Gemini ë³´ì™„ ë¶„ì„**: {gemini_result['executive_summary']}"
        )
    elif gemini_result.get("executive_summary"):
        merged["executive_summary"] = gemini_result["executive_summary"]
    
    # Key Findings í†µí•©
    if gemini_result.get("key_findings") and openai_result.get("key_findings"):
        merged_key_findings = openai_result["key_findings"].copy()
        
        # Primary Insights í†µí•© (ì¤‘ë³µ ì œê±°)
        if gemini_result["key_findings"].get("primary_insights"):
            openai_insights = set(openai_result["key_findings"].get("primary_insights", []))
            gemini_insights = gemini_result["key_findings"]["primary_insights"]
            
            # ìƒˆë¡œìš´ ì¸ì‚¬ì´íŠ¸ë§Œ ì¶”ê°€
            for insight in gemini_insights:
                if insight not in openai_insights:
                    merged_key_findings.setdefault("primary_insights", []).append(insight)
        
        # Quantitative Metrics í†µí•© (Gemini ê°’ìœ¼ë¡œ ë³´ì™„)
        if gemini_result["key_findings"].get("quantitative_metrics"):
            merged_metrics = openai_result["key_findings"].get("quantitative_metrics", {}).copy()
            gemini_metrics = gemini_result["key_findings"]["quantitative_metrics"]
            for key, value in gemini_metrics.items():
                if not merged_metrics.get(key) or merged_metrics[key] == "AI API í•„ìš”":
                    merged_metrics[key] = value
            merged_key_findings["quantitative_metrics"] = merged_metrics
        
        merged["key_findings"] = merged_key_findings
    elif gemini_result.get("key_findings"):
        merged["key_findings"] = gemini_result["key_findings"]
    
    # Detailed Analysis í†µí•©
    if gemini_result.get("detailed_analysis") and openai_result.get("detailed_analysis"):
        merged_detailed = openai_result["detailed_analysis"].copy()
        gemini_detailed = gemini_result["detailed_analysis"]
        
        # Insights í†µí•©
        if gemini_detailed.get("insights") and merged_detailed.get("insights"):
            merged_insights = merged_detailed["insights"].copy()
            gemini_insights = gemini_detailed["insights"]
            
            # ê° ì¸ì‚¬ì´íŠ¸ ì„¹ì…˜ í†µí•©
            for key, value in gemini_insights.items():
                if key not in merged_insights or not merged_insights[key]:
                    merged_insights[key] = value
                elif isinstance(value, dict) and isinstance(merged_insights[key], dict):
                    # ë”•ì…”ë„ˆë¦¬ì¸ ê²½ìš° ë³‘í•©
                    merged_insights[key] = {**merged_insights[key], **value}
                elif isinstance(value, list) and isinstance(merged_insights[key], list):
                    # ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° ì¤‘ë³µ ì œê±° í›„ ë³‘í•©
                    existing = set(str(item) for item in merged_insights[key])
                    for item in value:
                        if str(item) not in existing:
                            merged_insights[key].append(item)
            
            merged_detailed["insights"] = merged_insights
        
        merged["detailed_analysis"] = merged_detailed
    elif gemini_result.get("detailed_analysis"):
        merged["detailed_analysis"] = gemini_result["detailed_analysis"]
    
    # Strategic Recommendations í†µí•©
    if gemini_result.get("strategic_recommendations") and openai_result.get("strategic_recommendations"):
        merged_strategic = openai_result["strategic_recommendations"].copy()
        gemini_strategic = gemini_result["strategic_recommendations"]
        
        # ê° ì „ëµ ì„¹ì…˜ í†µí•©
        for key in ["immediate_actions", "short_term_strategies", "long_term_strategies"]:
            if gemini_strategic.get(key):
                openai_list = merged_strategic.get(key, [])
                gemini_list = gemini_strategic[key]
                
                # ì¤‘ë³µ ì œê±° í›„ ë³‘í•©
                existing = set(str(item) for item in openai_list)
                for item in gemini_list:
                    if str(item) not in existing:
                        openai_list.append(item)
                
                merged_strategic[key] = openai_list
        
        # Success MetricsëŠ” Gemini ê°’ìœ¼ë¡œ ë³´ì™„
        if gemini_strategic.get("success_metrics") and not merged_strategic.get("success_metrics"):
            merged_strategic["success_metrics"] = gemini_strategic["success_metrics"]
        
        merged["strategic_recommendations"] = merged_strategic
    elif gemini_result.get("strategic_recommendations"):
        merged["strategic_recommendations"] = gemini_result["strategic_recommendations"]
    
    # ë©”íƒ€ë°ì´í„° ì¶”ê°€
    merged["analysis_sources"] = ["openai", "gemini"]
    if "target_keyword" not in merged:
        merged["target_keyword"] = openai_result.get("target_keyword") or gemini_result.get("target_keyword")
    if "target_type" not in merged:
        merged["target_type"] = openai_result.get("target_type") or gemini_result.get("target_type")
    
    return merged


def _build_system_message(target_type: str) -> str:
    """ì‹œìŠ¤í…œ ë©”ì‹œì§€ ìƒì„±"""
    mece_instruction = """
CRITICAL: Your analysis MUST follow MECE (Mutually Exclusive, Collectively Exhaustive) principles:
- Mutually Exclusive: Each section and category must be distinct with no overlap
- Collectively Exhaustive: All relevant aspects must be covered comprehensively
- Logical Structure: Follow a clear, hierarchical, and logical flow
- Professional Format: Present findings in a structured, consulting-grade document format
"""
    
    if target_type == "audience":
        return f"""You are a senior marketing research and consulting analyst with 15+ years of experience at top-tier consulting firms (McKinsey, BCG, Bain, Deloitte, PwC).
Your role is to provide comprehensive, structured, and actionable audience analysis reports for C-level executives and marketing decision-makers.
{mece_instruction}
You MUST respond ONLY in valid JSON format without any markdown code blocks or additional text.
Your analysis must be:
- Data-driven with specific quantitative metrics and qualitative insights
- Structured in a logical, hierarchical manner following MECE principles
- Professional consulting-grade quality suitable for board presentations
- Actionable with clear strategic recommendations"""
    elif target_type == "keyword":
        return f"""You are a senior SEO and digital marketing strategy consultant with 15+ years of experience at top-tier consulting firms.
Your role is to provide comprehensive, structured, and actionable keyword analysis reports for digital marketing executives.
{mece_instruction}
You MUST respond ONLY in valid JSON format without any markdown code blocks or additional text.
Your analysis must be:
- Data-driven with specific quantitative metrics and qualitative insights
- Structured in a logical, hierarchical manner following MECE principles
- Professional consulting-grade quality suitable for strategic planning
- Actionable with clear SEO and marketing recommendations"""
    else:  # competitor
        return f"""You are a senior competitive intelligence and market research consultant with 15+ years of experience at top-tier consulting firms.
Your role is to provide comprehensive, structured, and actionable competitive analysis reports for strategic planning executives.
{mece_instruction}
You MUST respond ONLY in valid JSON format without any markdown code blocks or additional text.
Your analysis must be:
- Data-driven with specific quantitative metrics and qualitative insights
- Structured in a logical, hierarchical manner following MECE principles
- Professional consulting-grade quality suitable for board-level decisions
- Actionable with clear strategic recommendations and competitive positioning"""


def _build_analysis_prompt(
    target_keyword: str,
    target_type: str,
    additional_context: Optional[str],
    start_date: Optional[str] = None,
    end_date: Optional[str] = None
) -> str:
    """ë¶„ì„ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
    
    # ê¸°ê°„ ì •ë³´ ì¶”ê°€
    period_info = ""
    period_instruction = ""
    if start_date and end_date:
        period_info = f"""
**ë¶„ì„ ê¸°ê°„**: {start_date} ~ {end_date}
"""
        period_instruction = f"""
**ì¤‘ìš”**: ë°˜ë“œì‹œ {start_date}ë¶€í„° {end_date}ê¹Œì§€ì˜ ê¸°ê°„ ë™ì•ˆì˜ ë°ì´í„°, íŠ¸ë Œë“œ, ë³€í™”, íŒ¨í„´ì„ ì¤‘ì‹¬ìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”. 
ì´ ê¸°ê°„ ë™ì•ˆì˜ ì‹œê³„ì—´ ë³€í™”, ê³„ì ˆì„±, ì´ë²¤íŠ¸, ë‰´ìŠ¤, ì‹œì¥ ë™í–¥ ë“±ì„ ë°˜ë“œì‹œ í¬í•¨í•˜ì—¬ ë§¤ìš° ìƒì„¸í•˜ê²Œ ë¶„ì„í•´ì•¼ í•©ë‹ˆë‹¤.
"""
    elif start_date:
        period_info = f"""
**ì‹œì‘ì¼**: {start_date}
"""
        period_instruction = f"""
**ì¤‘ìš”**: ë°˜ë“œì‹œ {start_date} ì´í›„ì˜ íŠ¸ë Œë“œì™€ ë³€í™”ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”. 
ì´ ë‚ ì§œ ì´í›„ì˜ ì‹œê³„ì—´ ë³€í™”, ë‰´ìŠ¤, ì‹œì¥ ë™í–¥ ë“±ì„ ë°˜ë“œì‹œ í¬í•¨í•˜ì—¬ ë§¤ìš° ìƒì„¸í•˜ê²Œ ë¶„ì„í•´ì•¼ í•©ë‹ˆë‹¤.
"""
    elif end_date:
        period_info = f"""
**ì¢…ë£Œì¼**: {end_date}
"""
        period_instruction = f"""
**ì¤‘ìš”**: ë°˜ë“œì‹œ {end_date}ê¹Œì§€ì˜ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”. 
ì´ ë‚ ì§œê¹Œì§€ì˜ ì‹œê³„ì—´ ë³€í™”, ë‰´ìŠ¤, ì‹œì¥ ë™í–¥ ë“±ì„ ë°˜ë“œì‹œ í¬í•¨í•˜ì—¬ ë§¤ìš° ìƒì„¸í•˜ê²Œ ë¶„ì„í•´ì•¼ í•©ë‹ˆë‹¤.
"""
    
    # ì˜¤ë””ì–¸ìŠ¤ ë¶„ì„ì— íŠ¹í™”ëœ í”„ë¡¬í”„íŠ¸
    if target_type == "audience":
        prompt = f"""
ë‹¹ì‹ ì€ 10ë…„ ì´ìƒì˜ ê²½ë ¥ì„ ê°€ì§„ ì „ë¬¸ ë§ˆì¼€íŒ… ë° ì†Œë¹„ì í–‰ë™ ë¶„ì„ê°€ì…ë‹ˆë‹¤. 
ë‹¤ìŒ íƒ€ê²Ÿ ì˜¤ë””ì–¸ìŠ¤ì— ëŒ€í•œ ë§¤ìš° ìƒì„¸í•˜ê³  ì‹¬ì¸µì ì¸ ë§ˆì¼€íŒ… ê´€ì ì˜ ë¶„ì„ì„ ìˆ˜í–‰í•´ì£¼ì„¸ìš”.

**ë¶„ì„ ëŒ€ìƒ**: {target_keyword}
{period_info}
{period_instruction}

**ë¶„ì„ ëª©ì **: ì´ ë¶„ì„ì€ ë§ˆì¼€íŒ… ì „ëµ ìˆ˜ë¦½, íƒ€ê²ŸíŒ…, ë©”ì‹œì§•, ì±„ë„ ì„ íƒ, ì˜ˆì‚° ë°°ë¶„ ë“±ì˜ ì˜ì‚¬ê²°ì •ì— í™œìš©ë©ë‹ˆë‹¤.
ë”°ë¼ì„œ ëª¨ë“  ë¶„ì„ì€ ì‹¤í–‰ ê°€ëŠ¥í•œ ë§ˆì¼€íŒ… ì¸ì‚¬ì´íŠ¸ì™€ êµ¬ì²´ì ì¸ ì „ëµ ì œì•ˆì„ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.
"""
        if additional_context:
            prompt += f"""
**ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸**:
{additional_context}

"""
        prompt += """
ë‹¤ìŒ í•­ëª©ë“¤ì„ ë§¤ìš° ìƒì„¸í•˜ê²Œ ë¶„ì„í•˜ì—¬ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”. ê° í•­ëª©ì€ êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ì •ë³´ë¥¼ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤. 
íŠ¹íˆ ì§€ì •ëœ ê¸°ê°„ ë™ì•ˆì˜ ë³€í™”, íŠ¸ë Œë“œ, íŒ¨í„´ì„ ë°˜ë“œì‹œ í¬í•¨í•˜ì—¬ ë¶„ì„í•´ì£¼ì„¸ìš”:

{
  "executive_summary": "Executive Summary: ì˜¤ë””ì–¸ìŠ¤ì— ëŒ€í•œ ì¢…í•©ì ì¸ ìš”ì•½ (3-5ë¬¸ë‹¨, í•µì‹¬ ë°œê²¬ì‚¬í•­, ì£¼ìš” ì¸ì‚¬ì´íŠ¸, ì „ëµì  ê¶Œì¥ì‚¬í•­ ìš”ì•½)",
  "key_findings": {
    "primary_insights": [
      "ì¸êµ¬í†µê³„í•™ì  íŠ¹ì„±ì˜ í•µì‹¬ ìš”ì•½ (ì—°ë ¹ëŒ€, ì„±ë³„, ì§€ì—­, ì†Œë“ ìˆ˜ì¤€ ë“±)",
      "ì‹¬ë¦¬ì  íŠ¹ì„± ë° ë¼ì´í”„ìŠ¤íƒ€ì¼ì˜ ì£¼ìš” íŠ¹ì§•",
      "ì£¼ìš” í–‰ë™ íŒ¨í„´ ë° ë¯¸ë””ì–´ ì†Œë¹„ ìŠµê´€ì˜ íŠ¹ì§•",
      "í•µì‹¬ ë‹ˆì¦ˆ ë° í˜ì¸ í¬ì¸íŠ¸ (3-5ê°œ êµ¬ì²´ì  ì‚¬ë¡€)",
      "ì´ ì˜¤ë””ì–¸ìŠ¤ì˜ ê³ ìœ í•œ íŠ¹ì„±ê³¼ ì°¨ë³„ì "
    ],
    "quantitative_metrics": {
      "estimated_volume": "ì˜ˆìƒ ì˜¤ë””ì–¸ìŠ¤ ê·œëª¨ (êµ¬ì²´ì  ìˆ«ì ë˜ëŠ” ë²”ìœ„)",
      "engagement_level": "ì°¸ì—¬ ìˆ˜ì¤€ (ë‚®ìŒ/ì¤‘ê°„/ë†’ìŒ) ë° ê·¼ê±°",
      "growth_potential": "ì„±ì¥ ì ì¬ë ¥ (ë‚®ìŒ/ì¤‘ê°„/ë†’ìŒ) ë° ê·¼ê±°",
      "market_value": "ì‹œì¥ ê°€ì¹˜ ì¶”ì • (êµ¬ë§¤ë ¥, ì†Œë¹„ ê·œëª¨ ë“±)",
      "accessibility": "ì ‘ê·¼ ë‚œì´ë„ (ì´ ì˜¤ë””ì–¸ìŠ¤ì— ë„ë‹¬í•˜ê¸° ì–´ë ¤ìš´ ì •ë„)"
    }
  },
  "detailed_analysis": {
    "demographics": {
      "age_range": "ì£¼ìš” ì—°ë ¹ëŒ€ (ì˜ˆ: 25-35ì„¸) ë° ê° ì—°ë ¹ëŒ€ë³„ íŠ¹ì„±",
      "gender": "ì„±ë³„ ë¶„í¬ (ì˜ˆ: ë‚¨ì„± 60%, ì—¬ì„± 40%) ë° ì„±ë³„ë³„ íŠ¹ì„±",
      "location": "ì£¼ìš” ì§€ì—­ (ë„ì‹œ/ì§€ì—­ë³„ ë¶„í¬ ë° íŠ¹ì„±)",
      "income_level": "ì†Œë“ ìˆ˜ì¤€ (êµ¬ì²´ì  ê¸ˆì•¡ ë²”ìœ„ ë° ì†Œë¹„ íŒ¨í„´)",
      "education_level": "êµìœ¡ ìˆ˜ì¤€ ë° ì§ì—…êµ° ë¶„í¬",
      "family_status": "ê°€ì¡± êµ¬ì„± (1ì¸ ê°€êµ¬, ê¸°í˜¼, ìë…€ ìœ ë¬´ ë“±)",
      "expected_occupations": ["ì˜ˆìƒ ì§ì—… 1 (ìƒì„¸ ì„¤ëª… í¬í•¨)", "ì˜ˆìƒ ì§ì—… 2", "ì˜ˆìƒ ì§ì—… 3", "ì˜ˆìƒ ì§ì—… 4", "ì˜ˆìƒ ì§ì—… 5"]
    },
    "psychographics": {
      "lifestyle": "ë¼ì´í”„ìŠ¤íƒ€ì¼ íŠ¹ì„± (ì¼ìƒ íŒ¨í„´, ì—¬ê°€ í™œë™, ìƒí™œ ë°©ì‹ ë“± ìƒì„¸ ì„¤ëª…)",
      "values": "ê°€ì¹˜ê´€ ë° ì‹ ë… (ì¤‘ìš”í•˜ê²Œ ìƒê°í•˜ëŠ” ê°€ì¹˜ 5-7ê°œ)",
      "interests": "ì£¼ìš” ê´€ì‹¬ ë¶„ì•¼ (êµ¬ì²´ì ì¸ ê´€ì‹¬ì‚¬ ë° ì·¨ë¯¸)",
      "personality_traits": "ì„±ê²© íŠ¹ì„± (MBTI ìœ í˜• ì¶”ì •, ì£¼ìš” ì„±ê²© íŠ¹ì„±)",
      "aspirations": "ì—´ë§ ë° ëª©í‘œ (ì´ ì˜¤ë””ì–¸ìŠ¤ê°€ ì¶”êµ¬í•˜ëŠ” ê²ƒ)",
      "fears_concerns": "ìš°ë ¤ì‚¬í•­ ë° ë‘ë ¤ì›€ (ì´ ì˜¤ë””ì–¸ìŠ¤ê°€ ê±±ì •í•˜ëŠ” ê²ƒ)"
    },
    "behavior": {
      "purchase_behavior": "êµ¬ë§¤ í–‰ë™ íŒ¨í„´ (êµ¬ë§¤ ì£¼ê¸°, êµ¬ë§¤ ì±„ë„, êµ¬ë§¤ ê²°ì • ìš”ì¸, ê°€ê²© ë¯¼ê°ë„ ë“± ìƒì„¸ ì„¤ëª…)",
      "media_consumption": "ë¯¸ë””ì–´ ì†Œë¹„ íŒ¨í„´ (ì„ í˜¸í•˜ëŠ” ë¯¸ë””ì–´, ì†Œë¹„ ì‹œê°„, ì½˜í…ì¸  ì„ í˜¸ë„ ë“±)",
      "online_activity": "ì˜¨ë¼ì¸ í™œë™ íŠ¹ì„± (ì£¼ë¡œ ì‚¬ìš©í•˜ëŠ” í”Œë«í¼, ì˜¨ë¼ì¸ ì‡¼í•‘ íŒ¨í„´, SNS ì‚¬ìš© ë“±)",
      "brand_loyalty": "ë¸Œëœë“œ ì¶©ì„±ë„ (ë¸Œëœë“œ ì„ í˜¸ë„, ì „í™˜ ê°€ëŠ¥ì„± ë“±)",
      "decision_making": "ì˜ì‚¬ê²°ì • í”„ë¡œì„¸ìŠ¤ (êµ¬ë§¤ ê²°ì •ì— ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ìš”ì†Œ, ê²°ì • ì‹œê°„ ë“±)"
    },
    "trends": ["ì§€ì •ëœ ê¸°ê°„ ë™ì•ˆì˜ íŠ¸ë Œë“œ 1 (ìƒì„¸ ì„¤ëª… ë° ì‹œê³„ì—´ ë³€í™” í¬í•¨)", "íŠ¸ë Œë“œ 2", "íŠ¸ë Œë“œ 3", "íŠ¸ë Œë“œ 4", "íŠ¸ë Œë“œ 5"],
    "opportunities": ["ë§ˆì¼€íŒ… ê¸°íšŒ 1 (êµ¬ì²´ì  ì „ëµ í¬í•¨)", "ë§ˆì¼€íŒ… ê¸°íšŒ 2", "ë§ˆì¼€íŒ… ê¸°íšŒ 3", "ë§ˆì¼€íŒ… ê¸°íšŒ 4", "ë§ˆì¼€íŒ… ê¸°íšŒ 5"],
    "challenges": ["ë§ˆì¼€íŒ… ë„ì „ ê³¼ì œ 1 (í•´ê²° ë°©ì•ˆ í¬í•¨)", "ë§ˆì¼€íŒ… ë„ì „ ê³¼ì œ 2", "ë§ˆì¼€íŒ… ë„ì „ ê³¼ì œ 3", "ë§ˆì¼€íŒ… ë„ì „ ê³¼ì œ 4"]
  },
  "strategic_recommendations": {
    "immediate_actions": [
      "ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥í•œ ë§ˆì¼€íŒ… ì „ëµ 1 (êµ¬ì²´ì  ì‹¤í–‰ ë°©ì•ˆ, ì˜ˆìƒ íš¨ê³¼, í•„ìš” ë¦¬ì†ŒìŠ¤ í¬í•¨)",
      "ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥í•œ ë§ˆì¼€íŒ… ì „ëµ 2",
      "ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥í•œ ë§ˆì¼€íŒ… ì „ëµ 3"
    ],
    "short_term_strategies": [
      "ë‹¨ê¸° ë§ˆì¼€íŒ… ì „ëµ 1 (3-6ê°œì›”, êµ¬ì²´ì  ì‹¤í–‰ ë°©ì•ˆ í¬í•¨)",
      "ë‹¨ê¸° ë§ˆì¼€íŒ… ì „ëµ 2",
      "ë‹¨ê¸° ë§ˆì¼€íŒ… ì „ëµ 3"
    ],
    "long_term_strategies": [
      "ì¥ê¸° ë§ˆì¼€íŒ… ì „ëµ 1 (6ê°œì›” ì´ìƒ, êµ¬ì²´ì  ì‹¤í–‰ ë°©ì•ˆ í¬í•¨)",
      "ì¥ê¸° ë§ˆì¼€íŒ… ì „ëµ 2",
      "ì¥ê¸° ë§ˆì¼€íŒ… ì „ëµ 3"
    ],
    "success_metrics": "ì„±ê³µ ì§€í‘œ ë° ì¸¡ì • ë°©ë²• (KPI, ì¸¡ì • ì£¼ê¸°, ëª©í‘œ ìˆ˜ì¹˜ ë“±)"
  }
}
"""
    elif target_type == "keyword":
        # í‚¤ì›Œë“œ ë¶„ì„ì— íŠ¹í™”ëœ ë§¤ìš° ìƒì„¸í•œ í”„ë¡¬í”„íŠ¸
        prompt = f"""
ë‹¹ì‹ ì€ ê¸€ë¡œë²Œ ì»¨ì„¤íŒ… ê·¸ë£¹ì˜ ì‹œë‹ˆì–´ SEO ë° ë””ì§€í„¸ ë§ˆì¼€íŒ… ì „ëµ ì»¨ì„¤í„´íŠ¸ì…ë‹ˆë‹¤.
ë‹¤ìŒ í‚¤ì›Œë“œì— ëŒ€í•œ MECE ì›ì¹™ì— ê¸°ë°˜í•œ êµ¬ì¡°í™”ëœ ì»¨ì„¤íŒ… ìˆ˜ì¤€ì˜ ë¶„ì„ ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.

**ë¶„ì„ ëŒ€ìƒ í‚¤ì›Œë“œ**: {target_keyword}
{period_info}
{period_instruction}

**ë¶„ì„ ëª©ì **: ì´ ë¶„ì„ì€ ë””ì§€í„¸ ë§ˆì¼€íŒ… ì „ëµ ìˆ˜ë¦½, SEO ìµœì í™”, ì½˜í…ì¸  ê¸°íš, í‚¤ì›Œë“œ íƒ€ê²ŸíŒ…, ê²½ìŸ ë¶„ì„ ë“±ì˜ ì˜ì‚¬ê²°ì •ì— í™œìš©ë©ë‹ˆë‹¤.
ë”°ë¼ì„œ ëª¨ë“  ë¶„ì„ì€ ì‹¤í–‰ ê°€ëŠ¥í•œ SEO ì¸ì‚¬ì´íŠ¸ì™€ êµ¬ì²´ì ì¸ ìµœì í™” ì „ëµì„ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.

**MECE êµ¬ì¡° ìš”êµ¬ì‚¬í•­**:
1. Mutually Exclusive (ìƒí˜¸ ë°°íƒ€ì ): ê° ì„¹ì…˜ê³¼ ì¹´í…Œê³ ë¦¬ëŠ” ëª…í™•íˆ êµ¬ë¶„ë˜ì–´ ì¤‘ë³µì´ ì—†ì–´ì•¼ í•©ë‹ˆë‹¤.
2. Collectively Exhaustive (ì™„ì „ í¬ê´„ì ): í‚¤ì›Œë“œ ë¶„ì„ì— í•„ìš”í•œ ëª¨ë“  ì¸¡ë©´ì„ í¬ê´„í•´ì•¼ í•©ë‹ˆë‹¤.
3. ë…¼ë¦¬ì  ê³„ì¸µ êµ¬ì¡°: Executive Summary â†’ Key Findings â†’ Detailed Analysis â†’ Strategic Recommendations ìˆœì„œë¡œ êµ¬ì„±
4. ì»¨ì„¤íŒ… ë¬¸ì„œ í˜•ì‹: ëª…í™•í•œ êµ¬ì¡°, ë°ì´í„° ê¸°ë°˜ ê²°ë¡ , ì‹¤í–‰ ê°€ëŠ¥í•œ ê¶Œì¥ì‚¬í•­
"""
        if additional_context:
            prompt += f"""
**ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸**:
{additional_context}

"""
        prompt += """
**ì¤‘ìš” ì§€ì‹œì‚¬í•­**:
1. ë°˜ë“œì‹œ ìœ íš¨í•œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì•¼ í•©ë‹ˆë‹¤. ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡(```json)ì„ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.
2. MECE ì›ì¹™ì„ ì—„ê²©íˆ ì¤€ìˆ˜í•˜ì—¬ ê° ì„¹ì…˜ì´ ìƒí˜¸ ë°°íƒ€ì ì´ë©´ì„œ ì™„ì „ í¬ê´„ì ì´ì–´ì•¼ í•©ë‹ˆë‹¤.
3. ì •ëŸ‰ì  ë°ì´í„°(ê²€ìƒ‰ëŸ‰, ê²½ìŸë„ ì ìˆ˜, ì˜ˆìƒ ìˆ˜ì¹˜, ì‹œì¥ ê·œëª¨ ë“±)ì™€ ì •ì„±ì  ë¶„ì„(ì „ëµ, ê¸°íšŒ ë“±)ì„ ëª¨ë‘ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.
4. ì§€ì •ëœ ê¸°ê°„ ë™ì•ˆì˜ ê²€ìƒ‰ëŸ‰ ë³€í™”, íŠ¸ë Œë“œ, ê³„ì ˆì„±, ì´ë²¤íŠ¸ ë“±ì„ ë°˜ë“œì‹œ í¬í•¨í•˜ì—¬ ë¶„ì„í•´ì£¼ì„¸ìš”.
5. ì»¨ì„¤íŒ… ìˆ˜ì¤€ì˜ ì „ë¬¸ì„±: ë…¼ë¦¬ì  ê·¼ê±°, ë°ì´í„° ê¸°ë°˜ ê²°ë¡ , ì‹¤í–‰ ê°€ëŠ¥í•œ SEO ì „ëµì„ ì œì‹œí•´ì•¼ í•©ë‹ˆë‹¤.
6. ë¬¸ì„œ êµ¬ì¡°: Executive Summary â†’ Key Findings â†’ Detailed Analysis (MECE êµ¬ì¡°) â†’ Strategic Recommendations

ë‹¤ìŒ JSON êµ¬ì¡°ë¥¼ ì •í™•íˆ ë”°ë¥´ë©´ì„œ ê° í•„ë“œë¥¼ ë§¤ìš° ìƒì„¸í•˜ê²Œ ì‘ì„±í•´ì£¼ì„¸ìš”. ê° ì„¹ì…˜ì€ MECE ì›ì¹™ì— ë”°ë¼ ëª…í™•íˆ êµ¬ë¶„ë˜ì–´ì•¼ í•©ë‹ˆë‹¤:

{
  "executive_summary": "Executive Summary: í‚¤ì›Œë“œì— ëŒ€í•œ ì¢…í•©ì ì¸ ìš”ì•½ (3-5ë¬¸ë‹¨, í•µì‹¬ ë°œê²¬ì‚¬í•­, ì£¼ìš” ì¸ì‚¬ì´íŠ¸, ì „ëµì  ê¶Œì¥ì‚¬í•­ ìš”ì•½)",
  "key_findings": {
    "primary_insights": [
      "ê²€ìƒ‰ ì˜ë„ ë° ì‚¬ìš©ì ëª©ì ì˜ í•µì‹¬ ìš”ì•½",
      "ê²½ìŸ í™˜ê²½ ë° ì‹œì¥ ìƒí™©ì˜ ì£¼ìš” íŠ¹ì§•",
      "ê²€ìƒ‰ íŠ¸ë Œë“œ ë° ì‹œê³„ì—´ ë³€í™” íŒ¨í„´",
      "ê´€ë ¨ í‚¤ì›Œë“œ ë° ë¡±í…Œì¼ í‚¤ì›Œë“œ ê¸°íšŒ",
      "ì´ í‚¤ì›Œë“œì˜ ê³ ìœ í•œ íŠ¹ì„±ê³¼ ì°¨ë³„ì "
    ],
    "quantitative_metrics": {
      "estimated_volume": "ì˜ˆìƒ ê²€ìƒ‰ëŸ‰ (ì›”ê°„ ê²€ìƒ‰ëŸ‰ ë²”ìœ„ ë˜ëŠ” ì¶”ì •ì¹˜)",
      "competition_level": "ê²½ìŸ ìˆ˜ì¤€ (ë‚®ìŒ/ì¤‘ê°„/ë†’ìŒ) ë° êµ¬ì²´ì  ê·¼ê±°",
      "growth_potential": "ì„±ì¥ ì ì¬ë ¥ (ë‚®ìŒ/ì¤‘ê°„/ë†’ìŒ) ë° ê·¼ê±°",
      "difficulty_score": "ë‚œì´ë„ ì ìˆ˜ (1-100) ë° ê·¼ê±°",
      "opportunity_score": "ê¸°íšŒ ì ìˆ˜ (1-100) ë° ê·¼ê±°"
    }
  },
  "detailed_analysis": {
  "insights": {
    "search_intent": {
      "primary_intent": "ì£¼ìš” ê²€ìƒ‰ ì˜ë„ (Informational/Navigational/Transactional/Commercial) ë° ê·¼ê±°",
      "intent_breakdown": "ì˜ë„ë³„ ë¶„í¬ (ì˜ˆ: ì •ë³´ì„± 60%, ê±°ë˜ì„± 30%, íƒìƒ‰ì„± 10%)",
      "user_journey_stage": "ì‚¬ìš©ì ì—¬ì • ë‹¨ê³„ (ì¸ì§€/ê³ ë ¤/êµ¬ë§¤/ìœ ì§€) ë° ê° ë‹¨ê³„ë³„ íŠ¹ì„±",
      "search_context": "ê²€ìƒ‰ ë§¥ë½ (ì–¸ì œ, ì™œ, ì–´ë–»ê²Œ ê²€ìƒ‰í•˜ëŠ”ì§€)"
    },
    "competition": {
      "competition_level": "ê²½ìŸ ìˆ˜ì¤€ (ë‚®ìŒ/ì¤‘ê°„/ë†’ìŒ) ë° êµ¬ì²´ì  ê·¼ê±°",
      "top_competitors": ["ì£¼ìš” ê²½ìŸ í˜ì´ì§€/ì‚¬ì´íŠ¸ 1", "ì£¼ìš” ê²½ìŸ í˜ì´ì§€/ì‚¬ì´íŠ¸ 2", "ì£¼ìš” ê²½ìŸ í˜ì´ì§€/ì‚¬ì´íŠ¸ 3", "ì£¼ìš” ê²½ìŸ í˜ì´ì§€/ì‚¬ì´íŠ¸ 4", "ì£¼ìš” ê²½ìŸ í˜ì´ì§€/ì‚¬ì´íŠ¸ 5"],
      "competitor_analysis": "ê²½ìŸìë“¤ì˜ ê°•ì ê³¼ ì•½ì  ë¶„ì„",
      "market_gap": "ì‹œì¥ ê³µë°± ë° ì°¨ë³„í™” ê¸°íšŒ"
    },
    "trends": {
      "search_volume_trend": "ì§€ì •ëœ ê¸°ê°„ ë™ì•ˆì˜ ê²€ìƒ‰ëŸ‰ íŠ¸ë Œë“œ (ì¦ê°€/ê°ì†Œ/ì•ˆì •) ë° êµ¬ì²´ì  ë³€í™”ìœ¨, ì˜ˆìƒ ê²€ìƒ‰ëŸ‰ ë²”ìœ„",
      "seasonal_patterns": "ì§€ì •ëœ ê¸°ê°„ ë™ì•ˆì˜ ê³„ì ˆì„± íŒ¨í„´ (íŠ¹ì • ì‹œê¸°ì— ê²€ìƒ‰ëŸ‰ì´ ì¦ê°€/ê°ì†Œí•˜ëŠ”ì§€, êµ¬ì²´ì  ë‚ ì§œ ë° ì´ìœ )",
      "trending_topics": ["ì§€ì •ëœ ê¸°ê°„ ë™ì•ˆì˜ ê´€ë ¨ íŠ¸ë Œë”© í† í”½ 1 (ë°œìƒ ì‹œê¸° ë° ì´ìœ  í¬í•¨)", "íŠ¸ë Œë”© í† í”½ 2", "íŠ¸ë Œë”© í† í”½ 3", "íŠ¸ë Œë”© í† í”½ 4", "íŠ¸ë Œë”© í† í”½ 5"],
      "period_analysis": "ì§€ì •ëœ ê¸°ê°„ ë™ì•ˆì˜ ê²€ìƒ‰ëŸ‰ ë³€í™” ìƒì„¸ ë¶„ì„ (ì›”ë³„/ì£¼ë³„ ë³€í™”, í”¼í¬ ì‹œê¸°, í•˜ë½ ì‹œê¸° ë“±)",
      "future_outlook": "í–¥í›„ ì „ë§ (ì§€ì •ëœ ê¸°ê°„ì˜ íŒ¨í„´ì„ ê¸°ë°˜ìœ¼ë¡œ í•œ í–¥í›„ 6ê°œì›”-1ë…„ê°„ì˜ ì˜ˆìƒ íŠ¸ë Œë“œ)"
    },
    "related_keywords": {
      "semantic_keywords": ["ì˜ë¯¸ì ìœ¼ë¡œ ê´€ë ¨ëœ í‚¤ì›Œë“œ 1", "ì˜ë¯¸ì ìœ¼ë¡œ ê´€ë ¨ëœ í‚¤ì›Œë“œ 2", "ì˜ë¯¸ì ìœ¼ë¡œ ê´€ë ¨ëœ í‚¤ì›Œë“œ 3", "ì˜ë¯¸ì ìœ¼ë¡œ ê´€ë ¨ëœ í‚¤ì›Œë“œ 4", "ì˜ë¯¸ì ìœ¼ë¡œ ê´€ë ¨ëœ í‚¤ì›Œë“œ 5"],
      "long_tail_keywords": ["ë¡±í…Œì¼ í‚¤ì›Œë“œ 1 (ê²€ìƒ‰ëŸ‰ ë° ê²½ìŸë„ í¬í•¨)", "ë¡±í…Œì¼ í‚¤ì›Œë“œ 2", "ë¡±í…Œì¼ í‚¤ì›Œë“œ 3", "ë¡±í…Œì¼ í‚¤ì›Œë“œ 4", "ë¡±í…Œì¼ í‚¤ì›Œë“œ 5"],
      "question_keywords": ["ì§ˆë¬¸í˜• í‚¤ì›Œë“œ 1", "ì§ˆë¬¸í˜• í‚¤ì›Œë“œ 2", "ì§ˆë¬¸í˜• í‚¤ì›Œë“œ 3", "ì§ˆë¬¸í˜• í‚¤ì›Œë“œ 4", "ì§ˆë¬¸í˜• í‚¤ì›Œë“œ 5"],
      "comparison_keywords": ["ë¹„êµí˜• í‚¤ì›Œë“œ 1", "ë¹„êµí˜• í‚¤ì›Œë“œ 2", "ë¹„êµí˜• í‚¤ì›Œë“œ 3"]
    },
    "opportunities": ["SEO ê¸°íšŒ 1 (êµ¬ì²´ì  ì‹¤í–‰ ë°©ì•ˆ í¬í•¨)", "SEO ê¸°íšŒ 2", "SEO ê¸°íšŒ 3", "SEO ê¸°íšŒ 4", "SEO ê¸°íšŒ 5"],
    "challenges": ["SEO ë„ì „ ê³¼ì œ 1 (í•´ê²° ë°©ì•ˆ í¬í•¨)", "SEO ë„ì „ ê³¼ì œ 2", "SEO ë„ì „ ê³¼ì œ 3", "SEO ë„ì „ ê³¼ì œ 4"]
  },
  "strategic_recommendations": {
    "immediate_actions": [
      "ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥í•œ SEO ì „ëµ 1 (êµ¬ì²´ì  ì‹¤í–‰ ë°©ì•ˆ, ì˜ˆìƒ íš¨ê³¼, í•„ìš” ë¦¬ì†ŒìŠ¤ í¬í•¨)",
      "ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥í•œ SEO ì „ëµ 2",
      "ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥í•œ SEO ì „ëµ 3"
    ],
    "short_term_strategies": [
      "ë‹¨ê¸° SEO ì „ëµ 1 (3-6ê°œì›”, êµ¬ì²´ì  ì‹¤í–‰ ë°©ì•ˆ í¬í•¨)",
      "ë‹¨ê¸° SEO ì „ëµ 2",
      "ë‹¨ê¸° SEO ì „ëµ 3"
    ],
    "long_term_strategies": [
      "ì¥ê¸° SEO ì „ëµ 1 (6ê°œì›” ì´ìƒ, êµ¬ì²´ì  ì‹¤í–‰ ë°©ì•ˆ í¬í•¨)",
      "ì¥ê¸° SEO ì „ëµ 2",
      "ì¥ê¸° SEO ì „ëµ 3"
    ],
    "success_metrics": "ì„±ê³µ ì§€í‘œ ë° ì¸¡ì • ë°©ë²• (KPI, ì¸¡ì • ì£¼ê¸°, ëª©í‘œ ìˆ˜ì¹˜ ë“±)"
  },
  "target_audience": {
    "expected_occupations": ["ì´ í‚¤ì›Œë“œì™€ ê´€ë ¨ëœ ì£¼ìš” ì§ì—…êµ° 1", "ì§ì—…êµ° 2", "ì§ì—…êµ° 3", "ì§ì—…êµ° 4", "ì§ì—…êµ° 5"]
  }
}
"""
    else:  # competitor
        # ê²½ìŸì ë¶„ì„ì— íŠ¹í™”ëœ ë§¤ìš° ìƒì„¸í•œ í”„ë¡¬í”„íŠ¸
        prompt = f"""
ë‹¹ì‹ ì€ ê¸€ë¡œë²Œ ì»¨ì„¤íŒ… ê·¸ë£¹ì˜ ì‹œë‹ˆì–´ ê²½ìŸ ì¸í…”ë¦¬ì „ìŠ¤ ë° ì‹œì¥ ì¡°ì‚¬ ì»¨ì„¤í„´íŠ¸ì…ë‹ˆë‹¤.
ë‹¤ìŒ ê²½ìŸì‚¬ ë˜ëŠ” ê²½ìŸ í‚¤ì›Œë“œì— ëŒ€í•œ MECE ì›ì¹™ì— ê¸°ë°˜í•œ êµ¬ì¡°í™”ëœ ì»¨ì„¤íŒ… ìˆ˜ì¤€ì˜ ë¶„ì„ ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.

**ë¶„ì„ ëŒ€ìƒ**: {target_keyword}
{period_info}
{period_instruction}

**ë¶„ì„ ëª©ì **: ì´ ë¶„ì„ì€ ê²½ìŸ ì „ëµ ìˆ˜ë¦½, ì‹œì¥ í¬ì§€ì…”ë‹, ì°¨ë³„í™” ì „ëµ, ê°€ê²© ì „ëµ, ì‹œì¥ ì§„ì…/í™•ëŒ€ ì „ëµ ë“±ì˜ ì˜ì‚¬ê²°ì •ì— í™œìš©ë©ë‹ˆë‹¤.
ë”°ë¼ì„œ ëª¨ë“  ë¶„ì„ì€ ì‹¤í–‰ ê°€ëŠ¥í•œ ê²½ìŸ ì „ëµ ì¸ì‚¬ì´íŠ¸ì™€ êµ¬ì²´ì ì¸ ì°¨ë³„í™” ë°©ì•ˆì„ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.

**MECE êµ¬ì¡° ìš”êµ¬ì‚¬í•­**:
1. Mutually Exclusive (ìƒí˜¸ ë°°íƒ€ì ): ê° ì„¹ì…˜ê³¼ ì¹´í…Œê³ ë¦¬ëŠ” ëª…í™•íˆ êµ¬ë¶„ë˜ì–´ ì¤‘ë³µì´ ì—†ì–´ì•¼ í•©ë‹ˆë‹¤.
2. Collectively Exhaustive (ì™„ì „ í¬ê´„ì ): ê²½ìŸ ë¶„ì„ì— í•„ìš”í•œ ëª¨ë“  ì¸¡ë©´ì„ í¬ê´„í•´ì•¼ í•©ë‹ˆë‹¤.
3. ë…¼ë¦¬ì  ê³„ì¸µ êµ¬ì¡°: Executive Summary â†’ Key Findings â†’ Detailed Analysis â†’ Strategic Recommendations ìˆœì„œë¡œ êµ¬ì„±
4. ì»¨ì„¤íŒ… ë¬¸ì„œ í˜•ì‹: ëª…í™•í•œ êµ¬ì¡°, ë°ì´í„° ê¸°ë°˜ ê²°ë¡ , ì‹¤í–‰ ê°€ëŠ¥í•œ ê¶Œì¥ì‚¬í•­
"""
        if additional_context:
            prompt += f"""
**ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸**:
{additional_context}

"""
        prompt += """
**ì¤‘ìš” ì§€ì‹œì‚¬í•­**:
1. ë°˜ë“œì‹œ ìœ íš¨í•œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì•¼ í•©ë‹ˆë‹¤. ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡(```json)ì„ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.
2. MECE ì›ì¹™ì„ ì—„ê²©íˆ ì¤€ìˆ˜í•˜ì—¬ ê° ì„¹ì…˜ì´ ìƒí˜¸ ë°°íƒ€ì ì´ë©´ì„œ ì™„ì „ í¬ê´„ì ì´ì–´ì•¼ í•©ë‹ˆë‹¤.
3. ì •ëŸ‰ì  ë°ì´í„°(ì‹œì¥ ì ìœ ìœ¨, ê²½ìŸ ì ìˆ˜, ì˜ˆìƒ ìˆ˜ì¹˜, ì‹œì¥ ê·œëª¨ ë“±)ì™€ ì •ì„±ì  ë¶„ì„(ì „ëµ, ê¸°íšŒ ë“±)ì„ ëª¨ë‘ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.
4. ì§€ì •ëœ ê¸°ê°„ ë™ì•ˆì˜ ì‹œì¥ ë³€í™”, ê²½ìŸì ì›€ì§ì„, ì‹œì¥ ì ìœ ìœ¨ ë³€í™” ë“±ì„ ë°˜ë“œì‹œ í¬í•¨í•˜ì—¬ ë¶„ì„í•´ì£¼ì„¸ìš”.
5. ì»¨ì„¤íŒ… ìˆ˜ì¤€ì˜ ì „ë¬¸ì„±: ë…¼ë¦¬ì  ê·¼ê±°, ë°ì´í„° ê¸°ë°˜ ê²°ë¡ , ì‹¤í–‰ ê°€ëŠ¥í•œ ê²½ìŸ ì „ëµì„ ì œì‹œí•´ì•¼ í•©ë‹ˆë‹¤.
6. ë¬¸ì„œ êµ¬ì¡°: Executive Summary â†’ Key Findings â†’ Detailed Analysis (MECE êµ¬ì¡°) â†’ Strategic Recommendations

ë‹¤ìŒ JSON êµ¬ì¡°ë¥¼ ì •í™•íˆ ë”°ë¥´ë©´ì„œ ê° í•„ë“œë¥¼ ë§¤ìš° ìƒì„¸í•˜ê²Œ ì‘ì„±í•´ì£¼ì„¸ìš”. ê° ì„¹ì…˜ì€ MECE ì›ì¹™ì— ë”°ë¼ ëª…í™•íˆ êµ¬ë¶„ë˜ì–´ì•¼ í•©ë‹ˆë‹¤:

{
  "executive_summary": "Executive Summary: ê²½ìŸ í™˜ê²½ì— ëŒ€í•œ ì¢…í•©ì ì¸ ìš”ì•½ (3-5ë¬¸ë‹¨, í•µì‹¬ ë°œê²¬ì‚¬í•­, ì£¼ìš” ì¸ì‚¬ì´íŠ¸, ì „ëµì  ê¶Œì¥ì‚¬í•­ ìš”ì•½)",
  "key_findings": {
    "primary_insights": [
      "ê²½ìŸ í™˜ê²½ì˜ í•µì‹¬ ìš”ì•½ (ì‹œì¥ êµ¬ì¡°, ê²½ìŸ ê°•ë„ ë“±)",
      "ì£¼ìš” ê²½ìŸìì˜ ê°•ì ê³¼ ì•½ì ",
      "ì‹œì¥ í¬ì§€ì…”ë‹ ë° ì°¨ë³„í™” í¬ì¸íŠ¸",
      "ê²½ìŸ ìš°ìœ„ í™•ë³´ ê¸°íšŒ",
      "ì´ ì‹œì¥ì˜ ê³ ìœ í•œ íŠ¹ì„±ê³¼ ì°¨ë³„ì "
    ],
    "quantitative_metrics": {
      "competition_level": "ê²½ìŸ ìˆ˜ì¤€ (ë‚®ìŒ/ì¤‘ê°„/ë†’ìŒ) ë° êµ¬ì²´ì  ê·¼ê±°",
      "market_opportunity": "ì‹œì¥ ê¸°íšŒ í¬ê¸° (ë‚®ìŒ/ì¤‘ê°„/ë†’ìŒ) ë° ê·¼ê±°",
      "differentiation_potential": "ì°¨ë³„í™” ê°€ëŠ¥ì„± (ë‚®ìŒ/ì¤‘ê°„/ë†’ìŒ) ë° ê·¼ê±°",
      "risk_level": "ìœ„í—˜ ìˆ˜ì¤€ (ë‚®ìŒ/ì¤‘ê°„/ë†’ìŒ) ë° ì£¼ìš” ìœ„í—˜ ìš”ì†Œ",
      "success_probability": "ì„±ê³µ í™•ë¥  ì¶”ì • (ë‚®ìŒ/ì¤‘ê°„/ë†’ìŒ) ë° ê·¼ê±°"
    }
  },
  "detailed_analysis": {
    "competitive_environment": {
      "main_competitors": ["ì£¼ìš” ê²½ìŸì 1 (ìƒì„¸ ì •ë³´ í¬í•¨)", "ì£¼ìš” ê²½ìŸì 2", "ì£¼ìš” ê²½ìŸì 3", "ì£¼ìš” ê²½ìŸì 4", "ì£¼ìš” ê²½ìŸì 5"],
      "competition_intensity": "ê²½ìŸ ê°•ë„ (ë‚®ìŒ/ì¤‘ê°„/ë†’ìŒ) ë° êµ¬ì²´ì  ê·¼ê±°",
      "market_structure": "ì‹œì¥ êµ¬ì¡° (ê³¼ì /ë…ì /ì™„ì „ê²½ìŸ ë“±) ë° íŠ¹ì„±",
      "market_positioning": "ì‹œì¥ í¬ì§€ì…”ë‹ ë§µ (ê°€ê²©-í’ˆì§ˆ, ê¸°ëŠ¥-ì„œë¹„ìŠ¤ ë“±)",
      "barriers_to_entry": "ì§„ì… ì¥ë²½ (ê¸°ìˆ ì , ìë³¸ì , ê·œì œì  ë“±)",
      "market_size": "ì‹œì¥ ê·œëª¨ ì¶”ì • ë° ì„±ì¥ë¥ "
    },
    "competitor_analysis": {
      "strengths": ["ê²½ìŸìì˜ ì£¼ìš” ê°•ì  1 (êµ¬ì²´ì  ì‚¬ë¡€ í¬í•¨)", "ê°•ì  2", "ê°•ì  3", "ê°•ì  4", "ê°•ì  5"],
      "weaknesses": ["ê²½ìŸìì˜ ì•½ì  1 (êµ¬ì²´ì  ì‚¬ë¡€ í¬í•¨)", "ì•½ì  2", "ì•½ì  3", "ì•½ì  4", "ì•½ì  5"],
      "differentiation_points": ["ì°¨ë³„í™” í¬ì¸íŠ¸ 1 (êµ¬ì²´ì  ì „ëµ í¬í•¨)", "ì°¨ë³„í™” í¬ì¸íŠ¸ 2", "ì°¨ë³„í™” í¬ì¸íŠ¸ 3", "ì°¨ë³„í™” í¬ì¸íŠ¸ 4", "ì°¨ë³„í™” í¬ì¸íŠ¸ 5"],
      "market_share": "ì‹œì¥ ì ìœ ìœ¨ ì¶”ì • (ì£¼ìš” ê²½ìŸìë³„)",
      "pricing_strategy": "ê²½ìŸìì˜ ê°€ê²© ì „ëµ ë¶„ì„",
      "marketing_strategy": "ê²½ìŸìì˜ ë§ˆì¼€íŒ… ì „ëµ ë¶„ì„",
      "technology_stack": "ê²½ìŸìì˜ ê¸°ìˆ  ìŠ¤íƒ ë° í˜ì‹  ìˆ˜ì¤€"
    },
    "trends": {
      "market_trends": ["ì§€ì •ëœ ê¸°ê°„ ë™ì•ˆì˜ ì‹œì¥ íŠ¸ë Œë“œ 1 (ìƒì„¸ ì„¤ëª… ë° ì‹œê³„ì—´ ë³€í™” í¬í•¨)", "ì‹œì¥ íŠ¸ë Œë“œ 2", "ì‹œì¥ íŠ¸ë Œë“œ 3", "ì‹œì¥ íŠ¸ë Œë“œ 4", "ì‹œì¥ íŠ¸ë Œë“œ 5"],
      "competitor_movements": ["ì§€ì •ëœ ê¸°ê°„ ë™ì•ˆì˜ ê²½ìŸì ì›€ì§ì„ 1 (êµ¬ì²´ì  ì‹œê¸° ë° ë‚´ìš©)", "ê²½ìŸì ì›€ì§ì„ 2", "ê²½ìŸì ì›€ì§ì„ 3"],
      "industry_changes": "ì§€ì •ëœ ê¸°ê°„ ë™ì•ˆì˜ ì‚°ì—… ì „ë°˜ì˜ ë³€í™” ë° ì˜í–¥ (êµ¬ì²´ì  ì‹œê¸° ë° ì‚¬ê±´ í¬í•¨)",
      "period_analysis": "ì§€ì •ëœ ê¸°ê°„ ë™ì•ˆì˜ ì‹œì¥ ì ìœ ìœ¨, ê²½ìŸ ê°•ë„, ì§„ì…/í‡´ì¶œ ë“±ì˜ ë³€í™” ìƒì„¸ ë¶„ì„"
    },
    "opportunities": ["ê²½ìŸ ìš°ìœ„ í™•ë³´ ê¸°íšŒ 1 (êµ¬ì²´ì  ì‹¤í–‰ ë°©ì•ˆ í¬í•¨)", "ê¸°íšŒ 2", "ê¸°íšŒ 3", "ê¸°íšŒ 4", "ê¸°íšŒ 5"],
    "challenges": ["ê²½ìŸ ë„ì „ ê³¼ì œ 1 (í•´ê²° ë°©ì•ˆ í¬í•¨)", "ë„ì „ ê³¼ì œ 2", "ë„ì „ ê³¼ì œ 3", "ë„ì „ ê³¼ì œ 4"]
  },
  "strategic_recommendations": {
    "immediate_actions": [
      "ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥í•œ ê²½ìŸ ì „ëµ 1 (êµ¬ì²´ì  ì‹¤í–‰ ë°©ì•ˆ, ì˜ˆìƒ íš¨ê³¼, í•„ìš” ë¦¬ì†ŒìŠ¤ í¬í•¨)",
      "ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥í•œ ê²½ìŸ ì „ëµ 2",
      "ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥í•œ ê²½ìŸ ì „ëµ 3"
    ],
    "short_term_strategies": [
      "ë‹¨ê¸° ê²½ìŸ ì „ëµ 1 (3-6ê°œì›”, êµ¬ì²´ì  ì‹¤í–‰ ë°©ì•ˆ í¬í•¨)",
      "ë‹¨ê¸° ê²½ìŸ ì „ëµ 2",
      "ë‹¨ê¸° ê²½ìŸ ì „ëµ 3"
    ],
    "long_term_strategies": [
      "ì¥ê¸° ê²½ìŸ ì „ëµ 1 (6ê°œì›” ì´ìƒ, êµ¬ì²´ì  ì‹¤í–‰ ë°©ì•ˆ í¬í•¨)",
      "ì¥ê¸° ê²½ìŸ ì „ëµ 2",
      "ì¥ê¸° ê²½ìŸ ì „ëµ 3"
    ],
    "competitive_advantages": ["ê²½ìŸ ìš°ìœ„ í™•ë³´ ë°©ì•ˆ 1 (êµ¬ì²´ì  ì „ëµ í¬í•¨)", "ë°©ì•ˆ 2", "ë°©ì•ˆ 3"],
    "market_entry_strategy": "ì‹œì¥ ì§„ì… ì „ëµ (ì‹ ê·œ ì§„ì… ì‹œ) ë˜ëŠ” ì‹œì¥ í™•ëŒ€ ì „ëµ (ê¸°ì¡´ ì§„ì… ì‹œ)",
    "content_differentiation": ["ì½˜í…ì¸  ì°¨ë³„í™” ì „ëµ 1 (êµ¬ì²´ì  ì‹¤í–‰ ë°©ì•ˆ)", "ì „ëµ 2", "ì „ëµ 3"],
    "pricing_strategy": "ê°€ê²© ì „ëµ ì œì•ˆ (ê²½ìŸì ëŒ€ë¹„)",
    "partnership_opportunities": "íŒŒíŠ¸ë„ˆì‹­ ê¸°íšŒ ë° í˜‘ë ¥ ë°©ì•ˆ",
    "success_metrics": "ì„±ê³µ ì§€í‘œ ë° ì¸¡ì • ë°©ë²• (KPI, ì¸¡ì • ì£¼ê¸°, ëª©í‘œ ìˆ˜ì¹˜ ë“±)"
  }
}
"""
    
    return prompt
